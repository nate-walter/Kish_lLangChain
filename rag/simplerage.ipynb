{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='We Shall Fight on the Beaches, 1940\\n\\n\\nFrom the moment that the French defences at Sedan and on the Meuse were broken at the end of the second week of May, only a rapid retreat to Amiens and the south could have saved the British and French Armies who had entered Belgium at the appeal of the Belgian King; but this strategic fact was not immediately realised. The French High Command hoped they would be able to close the gap, and the Armies of the north were under their orders. Moreover, a retirement of this kind would have involved almost certainly the destruction of the fine Belgian Army of over 20 divisions and the abandonment of the whole of Belgium. Therefore, when the force and scope of the German penetration were realised and when a new French Generalissimo, General Weygand, assumed command in place of General Gamelin, an effort was made by the French and British Armies in Belgium to keep on holding the right hand of the Belgians and to give their own right hand to a newly created French Army which was to have advanced across the Somme in great strength to grasp it.\\n\\nHowever, the German eruption swept like a sharp scythe around the right and rear of the Armies of the north. Eight or nine armoured divisions, each of about four hundred armoured vehicles of different kinds, but carefully assorted to be complementary and divisible into small self-contained units, cut off all communications between us and the main French Armies. It severed our own communications for food and ammunition, which ran first to Amiens and afterwards through Abbeville, and it shore its way up the coast to Boulogne and Calais, and almost to Dunkirk. Behind this armoured and mechanised onslaught came a number of German divisions in lorries, and behind them again there plodded comparatively slowly the dull brute mass of the ordinary German Army and German people, always so ready to be led to the trampling down in other lands of liberties and comforts which they have never known in their own.\\n\\nI have said this armoured scythe-stroke almost reached Dunkirk-almost but not quite. Boulogne and Calais were the scenes of desperate fighting. The Guards defended Boulogne for a while and were then withdrawn by orders from this country. The Rifle Brigade, the 60th Rifles, and the Queen Victoria\\'s Rifles, with a battalion of British tanks and 1,000 Frenchmen, in all about four thousand strong, defended Calais to the last. The British Brigadier was given an hour to surrender. He spurned the offer, and four days of intense street fighting passed before silence reigned over Calais, which marked the end of a memorable resistance. Only 30 unwounded survivors were brought off by the Navy, and we do not know the fate of their comrades. Their sacrifice, however, was not in vain. At least two armoured divisions, which otherwise would have been turned against the British Expeditionary Force, had to be sent to overcome them. They have added another page to the glories of the light divisions, and the time gained enabled the Graveline water lines to be flooded and to be held by the French troops.\\n\\nThus it was that the port of Dunkirk was kept open. When it was found impossible for the Armies of the north to reopen their communications to Amiens with the main French Armies, only one choice remained. It seemed, indeed, forlorn. The Belgian, British and French Armies were almost surrounded. Their sole line of retreat was to a single port and to its neighboring beaches. They were pressed on every side by heavy attacks and far outnumbered in the air.\\n\\nWhen, a week ago today, I asked the House to fix this afternoon as the occasion for a statement, I feared it would be my hard lot to announce the greatest military disaster in our long history. I thought - and some good judges agreed with me -that perhaps 20,000 or 30,000 men might be re-embarked. But it certainly seemed that the whole of the French First Army and the whole of the British Expeditionary Force north of the Amiens-Abbeville gap would be broken up in the open field or else would have to capitulate for lack of food and ammunition. These were the hard and heavy tidings for which I called upon the House and the nation to prepare themselves a week ago. The whole root and core and brain of the British Army, on which and around which we were to build, and are to build, the great British Armies in the later years of the war, seemed about to perish upon the field or to be led into an ignominious and starving captivity.\\n\\nThat was the prospect a week ago. But another blow which might well have proved final was yet to fall upon us. The King of the Belgians had called upon us to come to his aid. Had not this Ruler and his Government severed themselves from the Allies, who rescued their country from extinction in the late war, and had they not sought refuge in what was proved to be a fatal neutrality, the French and British Armies might well at the outset have saved not only Belgium but perhaps even Poland. Yet at the last moment, when Belgium was already invaded, King Leopold called upon us to come to his aid, and even at the last moment we came. He and his brave, efficient Army, nearly half a million strong, guarded our left flank and thus kept open our only line of retreat to the sea. Suddenly, without prior consultation, with the least possible notice, without the advice of his Ministers and upon his own personal act, he sent a plenipotentiary to the German Command, surrendered his Army, and exposed our whole flank and means of retreat.\\n\\nI asked the House a week ago to suspend its judgement because the facts were not clear, but I do not feel that any reason now exists why we should not form our own opinions upon this pitiful episode. The surrender of the Belgian Army compelled the British at the shortest notice to cover a flank to the sea more than 30 miles in length. Otherwise all would have been cut off, and all would have shared the fate to which King Leopold had condemned the finest Army his country had ever formed. So in doing this and in exposing this flank, as anyone who followed the operations on the map will see, contact was lost between the British and two out of the three corps forming the First French Army, who were still farther from the coast than we were, and it seemed impossible that any large number of Allied troops could reach the coast.\\n\\nThe enemy attacked on all sides with great strength and fierceness, and their main power, the power of their far more numerous Air Force, was thrown into the battle or else concentrated upon Dunkirk and the beaches. Pressing in upon the narrow exit, both from the east and from the west, the enemy began to fire with cannon upon the beaches by which alone the shipping could approach or depart. They sowed magnetic mines in the channels and seas; they sent repeated waves of hostile aircraft, sometimes more than a hundred strong in one formation, to cast their bombs upon the single pier that remained, and upon the sand dunes upon which the troops had their eyes for shelter. Their U-boats, one of which was sunk, and their motor launches took their toll of the vast traffic which now began. For four or five days an intense struggle reigned. All their armoured divisions - or what was left of them - together with great masses of infantry and artillery, hurled themselves in vain upon the ever-narrowing, ever-contracting appendix within which the British and French Armies fought.\\n\\nMeanwhile, the Royal Navy, with the willing help of countless merchant seamen, strained every nerve to embark the British and Allied troops; 220 light warships and 650 other vessels were engaged. They had to operate upon the difficult coast, often in adverse weather, under an almost ceaseless hail of bombs and an increasing concentration of artillery fire. Nor were the seas, as I have said, themselves free from mines and torpedoes. It was in conditions such as these that our men carried on, with little or no rest, for days and nights on end, making trip after trip across the dangerous waters, bringing with them always men whom they had rescued. The numbers they have brought back are the measure of their devotion and their courage. The hospital ships, which brought off many thousands of British and French wounded, being so plainly marked were a special target for Nazi bombs; but the men and women on board them never faltered in their duty.\\n\\nMeanwhile, the Royal Air Force, which had already been intervening in the battle, so far as its range would allow, from home bases, now used part of its main metropolitan fighter strength, and struck at the German bombers and at the fighters which in large numbers protected them. This struggle was protracted and fierce. Suddenly the scene has cleared, the crash and thunder has for the moment - but only for the moment - died away. A miracle of deliverance, achieved by valour, by perseverance, by perfect discipline, by faultless service, by resource, by skill, by unconquerable fidelity, is manifest to us all. The enemy was hurled back by the retreating British and French troops. He was so roughly handled that he did not hurry their departure seriously. The Royal Air Force engaged the main strength of the German Air Force, and inflicted upon them losses of at least four to one; and the Navy, using nearly 1,000 ships of all kinds, carried over 335,000 men, French and British, out of the jaws of death and shame, to their native land and to the tasks which lie immediately ahead. We must be very careful not to assign to this deliverance the attributes of a victory. Wars are not won by evacuations. But there was a victory inside this deliverance, which should be noted. It was gained by the Air Force. Many of our soldiers coming back have not seen the Air Force at work; they saw only the bombers which escaped its protective attack. They underrate its achievements. I have heard much talk of this; that is why I go out of my way to say this. I will tell you about it.\\n\\nThis was a great trial of strength between the British and German Air Forces. Can you conceive a greater objective for the Germans in the air than to make evacuation from these beaches impossible, and to sink all these ships which were displayed, almost to the extent of thousands? Could there have been an objective of greater military importance and significance for the whole purpose of the war than this? They tried hard, and they were beaten back; they were frustrated in their task. We got the Army away; and they have paid fourfold for any losses which they have inflicted. Very large formations of German aeroplanes - and we know that they are a very brave race - have turned on several occasions from the attack of one-quarter of their number of the Royal Air Force, and have dispersed in different directions. Twelve aeroplanes have been hunted by two. One aeroplane was driven into the water and cast away by the mere charge of a British aeroplane, which had no more ammunition. All of our types - the Hurricane, the Spitfire and the new Defiant - and all our pilots have been vindicated as superior to what they have at present to face.\\n\\nWhen we consider how much greater would be our advantage in defending the air above this Island against an overseas attack, I must say that I find in these facts a sure basis upon which practical and reassuring thoughts may rest. I will pay my tribute to these young airmen. The great French Army was very largely, for the time being, cast back and disturbed by the onrush of a few thousands of armoured vehicles. May it not also be that the cause of civilisation itself will be defended by the skill and devotion of a few thousand airmen? There never has been, I suppose, in all the world, in all the history of war, such an opportunity for youth. The Knights of the Round Table, the Crusaders, all fall back into the past - not only distant but prosaic; these young men, going forth every morn to guard their native land and all that we stand for, holding in their hands these instruments of colossal and shattering power, of whom it may be said that\\n\\nEvery morn brought forth a noble chance\\nAnd every chance brought forth a noble knight,\\ndeserve our gratitude, as do all the brave men who, in so many ways and on so many occasions, are ready, and continue ready to give life and all for their native land.\\n\\nI return to the Army. In the long series of very fierce battles, now on this front, now on that, fighting on three fronts at once, battles fought by two or three divisions against an equal or somewhat larger number of the enemy, and fought fiercely on some of the old grounds that so many of us knew so well - in these battles our losses in men have exceeded 30,000 killed, wounded and missing. I take occasion to express the sympathy of the House to all who have suffered bereavement or who are still anxious. The President of the Board of Trade [Sir Andrew Duncan] is not here today. His son has been killed, and many in the House have felt the pangs of affliction in the sharpest form. But I will say this about the missing: We have had a large number of wounded come home safely to this country, but I would say about the missing that there may be very many reported missing who will come back home, some day, in one way or another. In the confusion of this fight it is inevitable that many have been left in positions where honour required no further resistance from them.\\n\\nAgainst this loss of over 30,000 men, we can set a far heavier loss certainly inflicted upon the enemy. But our losses in material are enormous. We have perhaps lost one-third of the men we lost in the opening days of the battle of 21st March, 1918, but we have lost nearly as many guns â€” nearly one thousand - and all our transport, all the armoured vehicles that were with the Army in the north. This loss will impose a further delay on the expansion of our military strength. That expansion had not been proceeding as far as we had hoped. The best of all we had to give had gone to the British Expeditionary Force, and although they had not the numbers of tanks and some articles of equipment which were desirable, they were a very well and finely equipped Army. They had the first-fruits of all that our industry had to give, and that is gone. And now here is this further delay. How long it will be, how long it will last, depends upon the exertions which we make in this Island. An effort the like of which has never been seen in our records is now being made. Work is proceeding everywhere, night and day, Sundays and week days. Capital and Labour have cast aside their interests, rights, and customs and put them into the common stock. Already the flow of munitions has leaped forward. There is no reason why we should not in a few months overtake the sudden and serious loss that has come upon us, without retarding the development of our general program.\\n\\nNevertheless, our thankfulness at the escape of our Army and so many men, whose loved ones have passed through an agonising week, must not blind us to the fact that what has happened in France and Belgium is a colossal military disaster. The French Army has been weakened, the Belgian Army has been lost, a large part of those fortified lines upon which so much faith had been reposed is gone, many valuable mining districts and factories have passed into the enemy\\'s possession, the whole of the Channel ports are in his hands, with all the tragic consequences that follow from that, and we must expect another blow to be struck almost immediately at us or at France. We are told that Herr Hitler has a plan for invading the British Isles. This has often been thought of before. When Napoleon lay at Boulogne for a year with his flat-bottomed boats and his Grand Army, he was told by someone. \"There are bitter weeds in England.\" There are certainly a great many more of them since the British Expeditionary Force returned.\\n\\nThe whole question of home defence against invasion is, of course, powerfully affected by the fact that we have for the time being in this Island incomparably more powerful military forces than we have ever had at any moment in this war or the last. But this will not continue. We shall not be content with a defensive war. We have our duty to our Ally. We have to reconstitute and build up the British Expeditionary Force once again, under its gallant Commander-in-Chief, Lord Gort. All this is in train; but in the interval we must put our defences in this Island into such a high state of organisation that the fewest possible numbers will be required to give effective security and that the largest possible potential of offensive effort may be realised. On this we are now engaged. It will be very convenient, if it be the desire of the House, to enter upon this subject in a secret Session. Not that the government would necessarily be able to reveal in very great detail military secrets, but we like to have our discussions free, without the restraint imposed by the fact that they will be read the next day by the enemy; and the Government would benefit by views freely expressed in all parts of the House by Members with their knowledge of so many different parts of the country. I understand that some request is to be made upon this subject, which will be readily acceded to by His Majesty\\'s Government.\\n\\nWe have found it necessary to take measures of increasing stringency, not only against enemy aliens and suspicious characters of other nationalities, but also against British subjects who may become a danger or a nuisance should the war be transported to the United Kingdom. I know there are a great many people affected by the orders which we have made who are the passionate enemies of Nazi Germany. I am very sorry for them, but we cannot, at the present time and under the present stress, draw all the distinctions which we should like to do. If parachute landings were attempted and fierce fighting attendant upon them followed, these unfortunate people would be far better out of the way, for their own sakes as well as for ours. There is, however, another class, for which I feel not the slightest sympathy. Parliament has given us the powers to put down Fifth Column activities with a strong hand, and we shall use those powers subject to the supervision and correction of the House, without the slightest hesitation until we are satisfied, and more than satisfied, that this malignancy in our midst has been effectively stamped out.\\n\\nTurning once again, and this time more generally, to the question of invasion, I would observe that there has never been a period in all these long centuries of which we boast when an absolute guarantee against invasion, still less against serious raids, could have been given to our people. In the days of Napoleon the same wind which would have carried his transports across the Channel might have driven away the blockading fleet. There was always the chance, and it is that chance which has excited and befooled the imaginations of many Continental tyrants. Many are the tales that are told. We are assured that novel methods will be adopted, and when we see the originality of malice, the ingenuity of aggression, which our enemy displays, we may certainly prepare ourselves for every kind of novel stratagem and every kind of brutal and treacherous maneuver. I think that no idea is so outlandish that it should not be considered and viewed with a searching, but at the same time, I hope, with a steady eye. We must never forget the solid assurances of sea power and those which belong to air power if it can be locally exercised.\\n\\nI have, myself, full confidence that if all do their duty, if nothing is neglected, and if the best arrangements are made, as they are being made, we shall prove ourselves once again able to defend our Island home, to ride out the storm of war, and to outlive the menace of tyranny, if necessary for years, if necessary alone.\\n\\nAt any rate, that is what we are going to try to do. That is the resolve of His Majesty\\'s Government - every man of them. That is the will of Parliament and the nation.\\n\\nThe British Empire and the French Republic, linked together in their cause and in their need, will defend to the death their native soil, aiding each other like good comrades to the utmost of their strength.\\n\\nEven though large tracts of Europe and many old and famous States have fallen or may fall into the grip of the Gestapo and all the odious apparatus of Nazi rule, we shall not flag or fail.\\n\\nWe shall go on to the end, we shall fight in France, we shall fight on the seas and oceans, we shall fight with growing confidence and growing strength in the air, we shall defend our Island, whatever the cost may be, we shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender, and even if, which I do not for a moment believe, this Island or a large part of it were subjugated and starving, then our Empire beyond the seas, armed and guarded by the British Fleet, would carry on the struggle, until, in God\\'s good time, the New World, with all its power and might, steps forth to the rescue and the liberation of the old.', metadata={'source': 'speech.txt'})]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Injestion\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = TextLoader(\"speech.txt\")\n",
    "text_documents = loader.load()\n",
    "text_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "load_dotenv()\n",
    "\n",
    "model = AzureOpenAI(\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_VERSION\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),    \n",
    ")\n",
    "\n",
    "# Initialize embeddings with Azure configuration\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    openai_api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_deployment=os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_VERSION\"),\n",
    "    # model=\"text-embedding-ada-002\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Welcome to the latest instalment in our LLM blog series! One of the most significant debates across generative AI revolves around the choice between Fine-tuning, Retrieval Augmented Generation (RAG) or a combination of both. In this blog post, we will explore both techniques, highlighting their strengths, weaknesses, and the factors that can help you make an informed choice for your LLM project. By the end of this blog, you will have a clear understanding of harnessing the full potential of these approaches to drive the success of your AI.This is the most basic RAG system, and you can refer to Enteprise architecture if you want to understand how to build one.Fine-Tuning vs. Retrieval Augmented Generation: A False DichotomyBefore diving into the comparison, it's crucial to understand that Fine-tuning and Retrieval Augmented Generation are not opposing techniques. Instead, they can be used in conjunction to leverage the strengths of each approach. Let’s explore this in detail.Language Modeling Task Fine-tuning:Purpose: Language model task fine-tuning is a broader approach that aims to adapt a pre-trained language model (like GPT-3 & Llama 2) to perform next token prediction.Training Data: The training data for language modeling task fine-tuning includes raw unsupervised text where we leverage the next token as the prediction label.Supervised Q&A Fine-tuningPurpose: Supervised Q&A fine-tuning is a more specialized form focusing on improving the model's performance in question-answering tasks.Training data: The training data for supervised Q&A fine-tuning consists of question-answer pairs. This data is used to fine-tune the model specifically for tasks where the input is a question, and the desired output is an answer.Distinct PurposesFine-tuning helps adapt the general language model to perform well on specific tasks, making it more task-specific.Retrieval Augmented Generation (RAG) focuses on connecting the LLM to external knowledge sources through retrieval mechanisms. It combines generative capabilities with the ability to search for and incorporate relevant information from a knowledge base.RAG and Fine-Tuning: Complementary RolesCombining RAG and fine-tuning in an LLM project offers a powerful synergy that can significantly enhance model performance and reliability. While RAG excels at providing access to dynamic external data sources and offers transparency in response generation, fine-tuning adds a crucial layer of adaptability and refinement. Without fine-tuning, the model can continue making the same mistakes. Fine-tuning allows for correcting such errors by fine-tuning the model with domain-specific and error-corrected data. Other benefits include learning the desired generation tone and handling the long tail of edge cases more gracefully.7 Factors to Consider When Evaluating Fine-Tuning and RAGRAGRAG excels in dynamic data environments. It continuously queries external sources, ensuring that the information remains up-to-date without frequent model retraining.Fine-TuningFine-tuned models become static data snapshots during training and may quickly become outdated in dynamic data scenarios. Furthermore, fine-tuning does not guarantee recall of this knowledge, making it unreliable.Conclusion: RAG offers agility and up-to-date responses in rapidly evolving data landscapes, making it ideal for projects with dynamic information needs.RAGRAG is designed to augment LLM capabilities by retrieving relevant information from knowledge sources before generating a response. It's ideal for applications that query databases, documents, or other structured/unstructured data repositories. RAG excels at leveraging external sources to enhance responses.Fine-TuningWhile it's possible to fine-tune an LLM to learn external knowledge, it may not be more practical for frequently changing data sources. Usually, training and evaluating models can be difficult and time-consuming.Conclusion: RAG is likely the better option if your application heavily relies on external data sources due to its flexibility and ability to adapt to changing information.RAGRAG primarily focuses on information retrieval and may not inherently adapt its linguistic style or domain-specificity based on the retrieved information. It excels at incorporating external knowledge but may not fully customize the model's behavior or writing style.Fine-TuningFine-tuning allows you to adapt an LLM's behavior, writing style, or domain-specific knowledge to specific nuances, tones, or terminologies. It offers deep alignment with particular styles or expertise areas.Conclusion: Fine-tuning offers a more direct route if your application demands specialized writing styles or deep alignment with domain-specific vocabulary and conventions.RAGRAG systems are inherently less prone to hallucination because they ground each response in retrieved evidence, reducing the model's ability to fabricate responses.Fine-TuningFine-tuning can help reduce hallucinations by grounding the model in a specific domain's training data. However, it may still fabricate responses when faced with unfamiliar inputs.Conclusion: RAG systems provide better mechanisms to minimize hallucinations for applications where suppressing falsehoods and imaginative fabrications is vital.RAGRAG systems offer transparency by breaking down response generation into distinct stages, providing insight into data retrieval and fostering trust in outputs.Fine-TuningFine-tuning operates like a black box, making the reasoning behind responses more opaque.Conclusion: RAG provides a clear advantage if transparency and interpretability are prioritiesRAGRAG does not allow us to use a smaller model.Fine-TuningFine-tuning can play a pivotal role in improving the effectiveness of small models, which in turn can lead to cheaper and faster inference. Smaller models require less hardware infrastructure for deployment and maintenance, which translates to cost savings in terms of cloud computing expenses or hardware procurement.Conclusion: When cost considerations are paramount, training and deploying smaller models can yield substantial savings, particularly at scale—advantage fine-tuning.RAGImplementing RAG typically requires a moderate to advanced level of technical expertise. Setting up the retrieval mechanisms, integrating with external data sources, and ensuring data freshness can be complex tasks. Additionally, designing efficient retrieval strategies and handling large-scale databases efficiently demand technical proficiency. However, various pre-built RAG frameworks and tools are available, simplifying the process to some extent.Fine-tuningFine-tuning, especially with large language models, demands high technical expertise. Preparing and curating high-quality training datasets, defining fine-tuning objectives, and managing the fine-tuning process are intricate tasks. Furthermore, fine-tuning often involves substantial computational resources, making it essential to have expertise in handling such infrastructure. Fine-tuning also requires understanding domain-specific nuances and creating appropriate evaluation metrics.Conclusion: RAG leans towards moderate technical expertise, mainly in data integration and retrieval mechanisms. Fine-tuning, on the other hand, demands a higher level of technical proficiency due to the complexities involved in data preparation, infrastructure management, and domain-specific adaptation.How Can We Apply This to Use Cases?Now, let's take what we've learned above and apply it to various use cases. We will consider different parameters for these use cases to determine the ultimate recommendation.Summarisation - Summarise articlesQuestion answering - Question-answering system on internal documents of a companyCustomer support chatbot - Answer queries of an e-commerce websiteCode generation - System to suggest code based on private + public codebaseAt Galileo, we're dedicated to enhancing the performance of your LLMs throughout the machine learning journey. If you're opting for the Retrieval Augmented Generation (RAG) approach, Galileo Prompt can assist you in optimizing your prompts and model settings. You can choose from predefined metrics or custom metrics to assess your system's performance.On the other hand, if you prefer the fine-tuning approach, Galileo Fine-Tune is your go-to tool. It helps identify errors in your training data, ultimately improving data quality. In both scenarios, our LLM Monitor enables real-time monitoring to detect and address hallucinations efficiently, ensuring a smoother and more reliable LLM experience.ConclusionWhen determining the best approach for your LLM project, it's essential to consider the specific requirements and limitations. Both approaches have their own strengths and weaknesses, and combining them might be the optimal solution. By choosing the right approach, you can unlock the full potential of your language model and create more reliable AI applications.Galileo LLM Studio is the leading platform for rapid evaluation, experimentation and observability for teams building LLM powered applications. It is powered by a suite of metrics to identify and mitigate hallucinations. Join 1000s of developers building apps powered by LLMs and get early access!\", metadata={'source': 'https://www.rungalileo.io/blog/optimizing-llm-performance-rag-vs-finetune-vs-both'})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "\n",
    "# Load, Chunk, and Index the content of the html page\n",
    "\n",
    "loader = WebBaseLoader(web_paths=(\"https://www.rungalileo.io/blog/optimizing-llm-performance-rag-vs-finetune-vs-both\",),\n",
    "                       bs_kwargs=dict(parse_only=bs4.SoupStrainer(\n",
    "                           class_=(\"my-4\",\n",
    "                                   \"mt-10 text-4xl font-normal leading-tight font-sora\", \n",
    "                                   \"mt-10 text-xl font-normal leading-tight font-sora\")\n",
    "                           )\n",
    "                        )\n",
    "                    )\n",
    "html_documents = loader.load()\n",
    "html_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Tree of Thoughts: Deliberate Problem Solving\\nwith Large Language Models\\nShunyu Yao\\nPrinceton UniversityDian Yu\\nGoogle DeepMindJeffrey Zhao\\nGoogle DeepMindIzhak Shafran\\nGoogle DeepMind\\nThomas L. Griffiths\\nPrinceton UniversityYuan Cao\\nGoogle DeepMindKarthik Narasimhan\\nPrinceton University\\nAbstract\\nLanguage models are increasingly being deployed for general problem solving\\nacross a wide range of tasks, but are still confined to token-level, left-to-right\\ndecision-making processes during inference. This means they can fall short in\\ntasks that require exploration, strategic lookahead, or where initial decisions play\\na pivotal role. To surmount these challenges, we introduce a new framework for\\nlanguage model inference, “Tree of Thoughts” (ToT), which generalizes over the\\npopular “Chain of Thought” approach to prompting language models, and enables\\nexploration over coherent units of text (“thoughts”) that serve as intermediate steps\\ntoward problem solving. ToT allows LMs to perform deliberate decision making\\nby considering multiple different reasoning paths and self-evaluating choices to\\ndecide the next course of action, as well as looking ahead or backtracking when\\nnecessary to make global choices. Our experiments show that ToT significantly\\nenhances language models’ problem-solving abilities on three novel tasks requiring\\nnon-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords.\\nFor instance, in Game of 24, while GPT-4 with chain-of-thought prompting only\\nsolved 4% of tasks, our method achieved a success rate of 74%. Code repo with all\\nprompts: https://github.com/princeton-nlp/tree-of-thought-llm .\\n1 Introduction\\nOriginally designed to generate text, scaled-up versions of language models (LMs) such as GPT [ 25,\\n26,1,23] and PaLM [ 5] have been shown to be increasingly capable of performing an ever wider\\nrange of tasks requiring mathematical, symbolic, commonsense, and knowledge reasoning. It is\\nperhaps surprising that underlying all this progress is still the original autoregressive mechanism for\\ngenerating text, which makes token-level decisions one by one and in a left-to-right fashion. Is such\\na simple mechanism sufficient for a LM to be built toward a general problem solver? If not, what\\nproblems would challenge the current paradigm, and what should be alternative mechanisms?\\nThe literature on human cognition provides some clues to answer these questions. Research on “dual\\nprocess” models suggests that people have two modes in which they engage with decisions – a fast,\\nautomatic, unconscious mode (“System 1”) and a slow, deliberate, conscious mode (“System 2”)\\n[30,31,16,15]. These two modes have previously been connected to a variety of mathematical\\nmodels used in machine learning. For example, research on reinforcement learning in humans and\\nother animals has explored the circumstances under which they engage in associative “model free”\\nlearning or more deliberative “model based” planning [ 7]. The simple associative token-level choices\\nof LMs are also reminiscent of “System 1”, and thus might benefit from augmentation by a more\\ndeliberate “System 2” planning process that (1) maintains and explores diverse alternatives for current\\n37th Conference on Neural Information Processing Systems (NeurIPS 2023).arXiv:2305.10601v2  [cs.CL]  3 Dec 2023', metadata={'source': 'tree_of_thought.pdf', 'page': 0}),\n",
       " Document(page_content='GĮŔũƜ\\njũƜŔũƜGĮŔũƜ\\njũƜŔũƜʱÊʲˤGjʱæʲˤ\\x1dĵÉGĮŔũƜ\\nˤjũƜŔũƜʱçʲˤ\\x1dĵÉˁ\\x92\\x1dʟʟʟʟaÊĠĵŗƓŤƆˤſĵŤòGĮŔũƜ\\nˤjũƜŔũƜʱíʲˤÉĵÉˤʱĵũŗŝʲʟʟʟʟʟʟˤˤʝˤƛĎĵũĈĎƜ)L[\\x03FRORU\\x03\\x0bE\\\\\\x03<XTLDQ\\x0c0DUN\\x03GLIIHUHQFH\\x03E\\\\\\x03FRORU\\nGĮŔũƜ\\njũƜŔũƜGĮŔũƜ\\njũƜŔũƜGĮŔũƜ\\nˤjũƜŔũƜʱçʲˤ\\x92òĦƙˤ\\x1dĵĮŝƓŝŤòĮçƆˤƀƓƜĎˤ\\x1dĵÉˤʱ\\x1dĵÉˁ\\x92\\x1dʲaÊĠĵŗƓŤƆˤſĵŤòGĮŔũƜ\\nˤjũƜŔũƜʱíʲˤÉŗòòˤĵƙˤ\\x9aĎĵũĈĎŤŝˤʱÉĵÉʲʟʟʟʟʟʟʟʟʟʟˤˤƛĎĵũĈĎƜ\\nʱçʲˤ\\x1dĎÊđĮˤĵƙˤ\\x9aĎĵũĈĎƜˤ\\x89ŗĵĭŔƜđĮĈˤʱ\\x1dĵÉʲʱÊʲˤGĮŔũƜˁjũƜŔũƜˤ\\x89ŗĵĭŔƜđĮĈˤʱGjʲFigure 1: Schematic illustrating various approaches to problem solving with LLMs. Each rectangle\\nbox represents a thought , which is a coherent language sequence that serves as an intermediate\\nstep toward problem solving. See concrete examples of how thoughts are generated, evaluated, and\\nsearched in Figures 2,4,6.\\nchoices instead of just picking one, and (2) evaluates its current status and actively looks ahead or\\nbacktracks to make more global decisions.\\nTo design such a planning process, we return to the origins of artificial intelligence (and cognitive\\nscience), drawing inspiration from the planning processes explored by Newell, Shaw, and Simon\\nstarting in the 1950s [ 21,22]. Newell and colleagues characterized problem solving [ 21] as search\\nthrough a combinatorial problem space, represented as a tree. We thus propose the Tree of Thoughts\\n(ToT) framework for general problem solving with language models. As Figure 1 illustrates, while\\nexisting methods (detailed below) sample continuous language sequences for problem solving, ToT\\nactively maintains a tree of thoughts, where each thought is a coherent language sequence that serves\\nas an intermediate step toward problem solving (Table 1). Such a high-level semantic unit allows the\\nLM to self-evaluate the progress different intermediate thoughts make towards solving the problem\\nthrough a deliberate reasoning process that is also instantiated in language (Figures 2,4,6). This\\nimplementation of search heuristics via LM self-evaluation and deliberation is novel, as previous\\nsearch heuristics are either programmed or learned. Finally, we combine this language-based\\ncapability to generate and evaluate diverse thoughts with search algorithms, such as breadth-first\\nsearch (BFS) or depth-first search (DFS), which allow systematic exploration of the tree of thoughts\\nwith lookahead and backtracking.\\nEmpirically, we propose three new problems that challenge existing LM inference methods even with\\nthe state-of-the-art language model, GPT-4 [ 23]: Game of 24, Creative Writing, and Crosswords\\n(Table 1). These tasks require deductive, mathematical, commonsense, lexical reasoning abilities,\\nand a way to incorporate systematic planning or search. We show ToT obtains superior results on\\nall three tasks by being general and flexible enough to support different levels of thoughts, different\\nways to generate and evaluate thoughts, and different search algorithms that adapt to the nature of\\ndifferent problems. We also analyze how such choices affect model performances via systematic\\nablations and discuss future directions to better train and use LMs.\\n2 Background\\nWe first formalize some existing methods that use large language models for problem-solving,\\nwhich our approach is inspired by and later compared with. We use pθto denote a pre-trained LM\\nwith parameters θ, and lowercase letters x, y, z, s, ···to denote a language sequence , i.e.x=\\n(x[1],···, x[n])where each x[i]is a token, so that pθ(x) =Qn\\ni=1pθ(x[i]|x[1...i]). We use uppercase\\nletters S,···to denote a collection of language sequences.\\nInput-output (IO) prompting is the most common way to turn a problem input xinto output\\nywith LM: y∼pθ(y|promptIO(x)), where promptIO(x)wraps input xwith task instructions\\nand/or few-shot input-output examples. For simplicity, let us denote pprompt\\nθ(output |input ) =\\npθ(output |prompt (input )), so that IO prompting can be formulated as y∼pIO\\nθ(y|x).\\n2', metadata={'source': 'tree_of_thought.pdf', 'page': 1}),\n",
       " Document(page_content='Chain-of-thought (CoT) prompting [38] was proposed to address cases where the mapping of\\ninput xto output yis non-trivial (e.g. when xis a math question and yis the final numerical answer).\\nThe key idea is to introduce a chain of thoughts z1,···, znto bridge xandy, where each ziis a\\ncoherent language sequence that serves as a meaningful intermediate step toward problem solving\\n(e.g.zicould be an intermediate equation for math QA). To solve problems with CoT, each thought\\nzi∼pCoT\\nθ(zi|x, z1···i−1)is sampled sequentially, then the output y∼pCoT\\nθ(y|x, z1···n). In\\npractice, [z1···n, y]∼pCoT\\nθ(z1···n, y|x)is sampled as a continuous language sequence, and the\\ndecomposition of thoughts (e.g. is each zia phrase, a sentence, or a paragraph) is left ambiguous.\\nSelf-consistency with CoT (CoT-SC) [36] is an ensemble approach that samples ki.i.d. chains\\nof thought: [z(i)\\n1···n, y(i)]∼pCoT\\nθ(z1···n, y|x) (i= 1···k), then returns the most frequent output:\\narg max y#{i|y(i)=y}. CoT-SC improves upon CoT, because there are generally different\\nthought processes for the same problem (e.g. different ways to prove the same theorem), and the\\noutput decision can be more faithful by exploring a richer set of thoughts. However, within each\\nchain there is no local exploration of different thought steps, and the “most frequent” heuristic only\\napplies when the output space is limited (e.g. multi-choice QA).\\n3 Tree of Thoughts: Deliberate Problem Solving with LM\\nA genuine problem-solving process involves the repeated use of available informa-\\ntion to initiate exploration, which discloses, in turn, more information until a way\\nto attain the solution is finally discovered.—— Newell et al. [21]\\nResearch on human problem-solving suggests that people search through a combinatorial problem-\\nspace – a tree where the nodes represent partial solutions, and the branches correspond to operators\\nthat modify them [ 21,22]. Which branch to take is determined by heuristics that help to navigate the\\nproblem-space and guide the problem-solver towards a solution. This perspective highlights two key\\nshortcomings of existing approaches that use LMs to solve general problems: 1) Locally, they do not\\nexplore different continuations within a thought process – the branches of the tree. 2) Globally, they\\ndo not incorporate any type of planning, lookahead, or backtracking to help evaluate these different\\noptions – the kind of heuristic-guided search that seems characteristic of human problem-solving.\\nTo address these shortcomings, we introduce Tree of Thoughts (ToT) , a paradigm that allows LMs to\\nexplore multiple reasoning paths over thoughts (Figure 1(c)). ToT frames any problem as a search\\nover a tree, where each node is a state s= [x, z1···i]representing a partial solution with the input and\\nthe sequence of thoughts so far. A specific instantiation of ToT involves answering four questions:\\n1. How to decompose the intermediate process into thought steps; 2. How to generate potential\\nthoughts from each state; 3. How to heuristically evaluate states; 4. What search algorithm to use.\\n1. Thought decomposition. While CoT samples thoughts coherently without explicit decomposition,\\nToT leverages problem properties to design and decompose intermediate thought steps. As Table 1\\nshows, depending on different problems, a thought could be a couple of words (Crosswords), a line of\\nequation (Game of 24), or a whole paragraph of writing plan (Creative Writing). In general, a thought\\nshould be “small” enough so that LMs can generate promising and diverse samples (e.g. generating\\na whole book is usually too “big” to be coherent), yet “big” enough so that LMs can evaluate its\\nprospect toward problem solving (e.g. generating one token is usually too “small” to evaluate).\\n2. Thought generator G(pθ, s, k).Given a tree state s= [x, z1···i], we consider two strategies to\\ngenerate kcandidates for the next thought step:\\n(a)Sample i.i.d. thoughts from a CoT prompt (Creative Writing, Figure 4): z(j)∼\\npCoT\\nθ(zi+1|s) =pCoT\\nθ(zi+1|x, z1···i) (j= 1···k). This works better when the thought\\nspace is rich (e.g. each thought is a paragraph), and i.i.d. samples lead to diversity;\\n(b)Propose thoughts sequentially using a “propose prompt” (Game of 24, Figure 2; Crosswords,\\nFigure 6): [z(1),···, z(k)]∼ppropose\\nθ(z(1···k)\\ni+1|s). This works better when the thought\\nspace is more constrained (e.g. each thought is just a word or a line), so proposing different\\nthoughts in the same context avoids duplication.\\n3. State evaluator V(pθ, S).Given a frontier of different states, the state evaluator evaluates the\\nprogress they make towards solving the problem, serving as a heuristic for the search algorithm\\nto determine which states to keep exploring and in which order. While heuristics are a standard\\napproach to solving search problems, they are typically either programmed (e.g. DeepBlue [ 3]) or\\n3', metadata={'source': 'tree_of_thought.pdf', 'page': 2}),\n",
       " Document(page_content='learned (e.g. AlphaGo [ 29]). We propose a third alternative, by using the LM to deliberately reason\\nabout states. When applicable, such a deliberate heuristic can be more flexible than programmed\\nrules, and more sample-efficient than learned models. Similar to the thought generator, we consider\\ntwo strategies to evaluate states either independently or together:\\n(a)Value each state independently: V(pθ, S)(s)∼pvalue\\nθ(v|s)∀s∈S, where a value\\nprompt reasons about the state sto generate a scalar value v(e.g. 1-10) or a classifica-\\ntion (e.g. sure/likely/impossible) that could be heuristically turned into a value. The basis\\nof such evaluative reasoning can vary across problems and thought steps. In this work, we\\nexplore evaluation via few lookahead simulations (e.g. quickly confirm that 5, 5, 14 can\\nreach 24 via 5 + 5 + 14, or “hot l” can mean “inn” via filling “e” in “ ”) plus commonsense\\n(e.g. 1 2 3 are too small to reach 24, or no word can start with “tzxc”). While the former\\nmight promote “good” states, the latter could help eliminate “bad” states. Such valuations\\ndo not need to be perfect, and only need to be approximately helpful for decision making.\\n(b)Vote across states: V(pθ, S)(s) =1[s=s∗], where a “good” state s∗∼pvote\\nθ(s∗|S)is\\nvoted out based on deliberately comparing different states in Sin a vote prompt. When\\nproblem success is harder to directly value (e.g. passage coherency), it is natural to to instead\\ncompare different partial solutions and vote for the most promising one. This is similar\\nin spirit to a “step-wise” self-consistency strategy, i.e. cast “which state to explore” as a\\nmulti-choice QA, and use LM samples to vote for it.\\nFor both strategies, we could prompt the LM multiple times to aggregate the value or vote results to\\ntrade time/resource/cost for more faithful/robust heuristics.\\nAlgorithm 1 ToT-BFS( x, pθ, G, k, V, T, b )\\nRequire: Input x, LM pθ, thought generator G()\\n& size limit k, states evaluator V(), step limit T,\\nbreadth limit b.\\nS0← {x}\\nfort= 1,···, Tdo\\nS′\\nt← {[s, z]|s∈St−1, zt∈G(pθ, s, k)}\\nVt←V(pθ, S′\\nt)\\nSt←arg max S⊂S′\\nt,|S|=bP\\ns∈SVt(s)\\nend for\\nreturn G(pθ,arg max s∈STVT(s),1)Algorithm 2 ToT-DFS( s, t, p θ, G, k, V, T, v th)\\nRequire: Current state s, step t, LM pθ, thought\\ngenerator G()and size limit k, states evaluator\\nV(), step limit T, threshold vth\\nift > T then record output G(pθ, s,1)\\nend if\\nfors′∈G(pθ, s, k)do ▷sorted candidates\\nifV(pθ,{s′})(s)> vthres then ▷pruning\\nDFS(s′, t+ 1)\\nend if\\nend for\\n4. Search algorithm. Finally, within the ToT framework, one can plug and play different search\\nalgorithms depending on the tree structure. We explore two relatively simple search algorithms and\\nleave more advanced ones (e.g. A* [11], MCTS [2]) for future work:\\n(a)Breadth-first search (BFS) (Algorithm 1) maintains a set of the bmost promising states\\nper step. This is used for Game of 24 and Creative Writing where the tree depth is limit\\n(T≤3), and initial thought steps can be evaluated and pruned to a small set ( b≤5).\\n(b)Depth-first search (DFS) (Algorithm 2) explores the most promising state first, until the\\nfinal output is reached ( t > T ), or the state evaluator deems it impossible to solve the\\nproblem from the current s(V(pθ,{s})(s)≤vthfor a value threshold vth). In the latter\\ncase, the subtree from sispruned to trade exploration for exploitation. In both cases, DFS\\nbacktracks to the parent state of sto continue exploration.\\nConceptually, ToT has several benefits as a method for general problem-solving with LMs: (1) Gener-\\nality. IO, CoT, CoT-SC, and self-refinement can be seen as special cases of ToT (i.e. trees of limited\\ndepth and breadth; Figure 1). (2) Modularity. The base LM, as well as the thought decomposition,\\ngeneration, evaluation, and search procedures can all be varied independently. (3) Adaptability .\\nDifferent problem properties, LM capabilities, and resource constraints can be accommodated. (4)\\nConvenience. No extra training is needed, just a pre-trained LM is sufficient. The next section will\\nshow how these conceptual benefits translate to strong empirical performance in different problems.\\n4 Experiments\\nWe propose three tasks that are hard even when sampling from the state-of-the-art language model,\\nGPT-4 [ 23], using standard IO prompting or chain-of-thought (CoT) prompting. We show how\\n4', metadata={'source': 'tree_of_thought.pdf', 'page': 3}),\n",
       " Document(page_content='Game of 24 Creative Writing 5x5 Crosswords\\nInput 4 numbers (4 9 10 13) 4 random sentences 10 clues (h1. presented;..)\\nOutput An equation to reach 24\\n(13-9)*(10-4)=24A passage of 4 paragraphs\\nending in the 4 sentences5x5 letters: SHOWN;\\nWIRRA; A V AIL; ...\\nThoughts 3 intermediate equations\\n(13-9=4 (left 4,4,10); 10-\\n4=6 (left 4,6); 4*6=24)A short writing plan\\n(1. Introduce a book that\\nconnects...)Words to fill in for clues:\\n(h1. shown; v5. naled; ...)\\n#ToT steps 3 1 5-10 (variable)\\nTable 1: Task overview. Input, output, thought examples are in blue.\\ndeliberate search in trees of thoughts (ToT) produces better results, and more importantly, interesting\\nand promising new ways to use language models to solve problems requiring search or planning.\\nUnless otherwise stated, we perform experiments using a Chat Completion mode GPT-41with a\\nsampling temperature of 0.7.\\n4.1 Game of 24\\nGame of 24 is a mathematical reasoning challenge, where the goal is to use 4 numbers and basic\\narithmetic operations (+-*/) to obtain 24. For example, given input “4 9 10 13”, a solution output\\ncould be “(10 - 4) * (13 - 9) = 24”.\\nʳĵĮòˤòƅÊĭŔĦòʴˤGĮŔũƜʝˤʁˤʆˤɾɽˤɾʀ\\x89ĵŝŝđæĦòˤĮòƅƜˤŝŤòŔŝʝˤˤˤ3URSRVH\\x033URPSWʁˤ̌ˤʆˤ̐ˤɾʀˤʱĦòƙƜʝˤɾɽˤɾʀˤɾʀʲɾɽˤˊˤʁˤ̐ˤʃˤʱĦòƙƜʝˤʃˤʆˤɾʀʲʳʛʛʛĭĵŗòˤĦđĮòŝʟʴ7KRXJKW\\x03*HQHUDWLRQ/0)ſÊĦũÊŤòˤđƙˤĈƓſòĮˤĮũĭæòŗŝˤçÊĮˤŗòÊçĎˤɿʁˤʱŝũŗòʫĦđģòĦƆʫđĭŔĵŝŝđæĦòʲɾɽˤɾʁʝˤɾɽˤ̌ˤɾʁˤ̐ˤɿʁʛˤŝũŗòʳĭĵŗòˤòƅÊĭŔĦòŝʴɾɽˤɾʀˤɾʀ9DOXH\\x033URPSWʱɾʀˤˊˤɾɽʲˤʦˤɾʀˤ̐ˤʀˤʦˤɾʀˤ̐ˤʀʆɾɽˤ̌ˤɾʀˤ̌ˤɾʀˤ̐ˤʀʃ\\x9aĎòŗòˤƓŝˤĮĵˤƀÊƆˤƘĵˤĵæŤÊđĮˤɿʁˤƀƓƜĎˤƛĎòŝòˤĮũĭæòŗŝʛˤđĭŔĵŝŝđæĦò7KRXJKW\\x03(YDOXDWLRQʱæʲʱçʲ/0GĮŔũƜʝˤʁˤʆˤɾɽˤɾʀʁ̌ʆ̐ɾʀʱĦòƙƜʝˤɾɽˤɾʀˤɾʀʲɾɽˁʁ̐ʃʱĦòƙƜʝˤʃˤʆˤɾʀʲʟʟɾʀˁʃ̐ʄʱĦòƙƜʝˤʄˤʆʲɾʀˁʆ̐ʁʱĦòƙƜʝˤʁˤʃʲʟʟʁʦʃ̐ɿʁʱĦòƙƜʝˤɿʁʲʁ̌ʃ̐ɾɽʱĦòƙƜʝˤɾɽʲʟʟʱÊʲ\\nʳĵĮòˤòƅÊĭŔĦòʴˤGĮŔũƜʝˤʁˤʆˤɾɽˤɾʀ\\x89ĵŝŝđæĦòˤĮòƅƜˤŝŤòŔŝʝˤˤˤ\\x0bD\\x0c\\x033URSRVH\\x033URPSWʁˤ̌ˤʆˤ̐ˤɾʀˤʱĦòƙƜʝˤɾɽˤɾʀˤɾʀʲɾɽˤˊˤʁˤ̐ˤʃˤʱĦòƙƜʝˤʃˤʆˤɾʀʲʳʛʛʛĭĵŗòˤĦđĮòŝʟʴ7KRXJKW\\x03*HQHUDWLRQ/0)ſÊĦũÊŤòˤđƙˤĈƓſòĮˤĮũĭæòŗŝˤçÊĮˤŗòÊçĎˤɿʁˤʱŝũŗòʫĦđģòĦƆʫđĭŔĵŝŝđæĦòʲɾɽˤɾʁʝˤɾɽˤ̌ˤɾʁˤ̐ˤɿʁʛˤŝũŗòʳĭĵŗòˤòƅÊĭŔĦòŝʴɾɽˤɾʀˤɾʀ\\x0bE\\x0c\\x039DOXH\\x033URPSWʱɾʀˤˊˤɾɽʲˤʦˤɾʀˤ̐ˤʀˤʦˤɾʀˤ̐ˤʀʆɾɽˤ̌ˤɾʀˤ̌ˤɾʀˤ̐ˤʀʃˤ\\x9aĎòŗòˤƓŝˤĮĵˤƀÊƆˤƘĵˤĵæŤÊđĮˤɿʁˤƀƓƜĎˤƛĎòŝòˤæƓĈˤĮũĭæòŗŝʛˤđĭŔĵŝŝđæĦò7KRXJKW\\x03(YDOXDWLRQ/0GĮŔũƜʝˤʁˤʆˤɾɽˤɾʀʁ̌ʆ̐ɾʀʱĦòƙƜʝˤɾɽˤɾʀˤɾʀʲɾɽˁʁ̐ʃʱĦòƙƜʝˤʃˤʆˤɾʀʲʟʟɾʀˁʃ̐ʄʱĦòƙƜʝˤʄˤʆʲɾʀˁʆ̐ʁʱĦòƙƜʝˤʁˤʃʲʟʟʁʦʃ̐ɿʁʱĦòƙƜʝˤɿʁʲʁ̌ʃ̐ɾɽʱĦòƙƜʝˤɾɽʲʟʟ)L[\\x03FRORU\\x03\\x0bE\\\\\\x03<XTLDQ\\x0c0DUN\\x03GLII\\x03SURPSW\\x03ZLWK\\x03FRORU\\nFigure 2: ToT in a game of 24. The LM is prompted for (a) thought generation and (b) valuation.\\nTask Setup. We scrape data from 4nums.com, which has 1,362 games that are sorted from easy to\\nhard by human solving time, and use a subset of relatively hard games indexed 901-1,000 for testing.\\nFor each task, we consider the output as success if it is a valid equation that equals 24 and uses the\\ninput numbers each exactly once. We report the success rate across 100 games as the metric.\\nBaselines. We use a standard input-output (IO) prompt with 5 in-context examples. For chain-of-\\nthought (CoT) prompting, we augment each input-output pair with 3 intermediate equations, each\\noperating on two remaining numbers. For example, given input “4 9 10 13”, the thoughts could be\\n“13 - 9 = 4 (left: 4 4 10); 10 - 4 = 6 (left: 4 6); 4 * 6 = 24 (left: 24)”. For each game, we sample IO\\nand CoT prompting for 100 times for average performance. We also consider a CoT self-consistency\\nbaseline, which takes the majority output from 100 CoT samples, and an iterative-refine approach on\\ntop of an IO sample for at most 10iterations. At each iteration, the LM is conditioned on all previous\\nhistory to “reflect on your mistakes and generate a refined answer” if the output is incorrect. Note\\nthat it uses groundtruth feedback signals about equation correctness.\\nToT Setup. To frame Game of 24 into ToT, it is natural to decompose the thoughts into 3 steps,\\neach an intermediate equation. As shown in Figure 2(a), at each tree node, we exact the remaining\\nnumbers and prompt the LM to propose some possible next steps. The same “propose prompt” is\\nused for all 3 thought steps, though it only has one example with 4 input numbers. We perform a\\nbreadth-first search (BFS) in ToT, where at each step we keep the best b= 5candidates. To perform\\ndeliberate BFS in ToT, as shown in Figure 2(b), we prompt LM to evaluate each thought candidate as\\n“sure/maybe/impossible” with regard to reaching 24. The aim is to promote correct partial solutions\\nthat can be verdicted within few lookahead trials, and eliminate impossible partial solutions based on\\n“too big/small” commonsense, and keep the rest “maybe”. We sample values 3times for each thought.\\n1Experiments were done between May 5-16, 2023.\\n5', metadata={'source': 'tree_of_thought.pdf', 'page': 4}),\n",
       " Document(page_content='Method Success\\nIO prompt 7.3%\\nCoT prompt 4.0%\\nCoT-SC (k=100) 9.0%\\nToT (ours) (b=1) 45%\\nToT (ours) (b=5) 74%\\nIO + Refine (k=10) 27%\\nIO(best of 100) 33%\\nCoT (best of 100) 49%\\nTable 2: Game of 24 Results.\\n0 25 50 75 1000.20.40.6(a) Success rate with nodes visited\\nIO (best of k)\\nCoT (best of k)\\nToT (b=1...5)\\n1 2 3 4Correct0.00.20.40.6(b) Samples failed at each step\\nCoT\\nToT (b=5) Figure 3: Game of 24 (a) scale analysis & (b) error analysis.\\nResults. As shown in Table 2, IO, CoT, and CoT-SC prompting methods perform badly on the task,\\nachieving only 7.3%, 4.0%, and 9.0% success rates. In contrast, ToT with a breadth of b= 1already\\nachieves a success rate of 45%, while b= 5 achieves 74%. We also consider an oracle setup for\\nIO/CoT, by calculating the success rate using best of ksamples (1≤k≤100) . To compare IO/CoT\\n(best of k) with ToT, we consider calculating the tree nodes visited per task in ToT across b= 1···5,\\nand map the 5 success rates in Figure 3(a), treating IO/CoT (best of k) as visiting knodes in a bandit.\\nNot surprisingly, CoT scales better than IO, and best of 100 CoT samples achieve a success rate of\\n49%, but still much worse than exploring more nodes in ToT ( b >1).\\nError analysis. Figure 3(b) breaks down at which step CoT and ToT samples fail the task, i.e. the\\nthought (in CoT) or all bthoughts (in ToT) are invalid or impossible to reach 24. Notably, around\\n60% of CoT samples already failed the task after generating the first step, or equivalently, the first\\nthree words (e.g. “ 4 + 9 ”). This highlights the issues with direct left-to-right decoding.\\n4.2 Creative writing\\nNext, we invent a creative writing task where the input is 4 random sentences and the output should\\nbe a coherent passage with 4 paragraphs that end in the 4 input sentences respectively. Such a task is\\nopen-ended and exploratory, and challenges creative thinking as well as high-level planning.\\nTask setup. We sample random sentences from randomwordgenerator.com to form 100 inputs, and\\nthere is no groundtruth passage for each input constraint. As we find that GPT-4 can follow the\\ninput constraints most of the time, we focus on evaluating passage coherency in two ways: using a\\nGPT-4 zero-shot prompt to provide a 1-10 scalar score, or using human judgments to compare pairs\\nof outputs from different methods. For the former, we sample 5 scores and average them for each task\\noutput, and we find these 5 scores usually consistent, with a standard deviation of around 0.56on\\naverage across outputs. For the latter, we employ a subset of the authors in a blind study to compare\\nthe coherency of CoT vs. ToT generated passage pairs, where the order of passages is random flipped\\nover 100 inputs.\\nBaselines. Given the creative nature of the task, both IO and CoT prompts are zero-shot. While the\\nformer prompts the LM to directly generate a coherent passage given input constraints, the latter\\nprompts the LM to first make a brief plan then write the passage, i.e. the plan serves as the intermediate\\nthought step. We generate 10 IO and CoT samples per task. We also consider an iterative-refine\\n(k≤5) method on top of a random IO sample for each task, where the LM is conditioned on input\\nconstraints and the last generated passage to decide if the passage is already “perfectly coherent”,\\nand if not generate a refined one.\\nToT setup. We build a ToT with depth 2 (and only 1 intermediate thought step) — the LM first\\ngenerates k= 5plans and votes for the best one (Figure 4), then similarly generate k= 5passages\\nbased on the best plan then vote for the best one. Here the breadth limit b= 1, as only one choice is\\nkept per step. A simple zero-shot vote prompt (“analyze choices below, then conclude which is most\\npromising for the instruction”) is used to sample 5 votes at both steps.\\nResults. Figure 5(a) shows average GPT-4 scores across 100 tasks, where ToT (7.56) is deemed to\\ngenerate more coherent passages than IO (6.19) and CoT (6.93) on average. While such an automatic\\nmetric might be noisy, Figure 5(b) confirms the finding by showing that humans prefer ToT over\\nCoT in 41 out of 100 passage pairs, while only prefer CoT over ToT in 21 (other 38 pairs are found\\n“similarly coherent”). Lastly, iterative-refine is more effective on this natural language task, where\\n6', metadata={'source': 'tree_of_thought.pdf', 'page': 5}),\n",
       " Document(page_content='µŗƓŤòˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòˤĵƙˤʁˤŝĎĵŗƜˤŔÊŗÊĈŗÊŔĎŝʛˤ\\x9aĎòˤòĮíˤŝòĮŤòĮçòˤĵƙˤòÊçĎˤŔÊŗÊĈŗÊŔĎˤĭũŝƜˤæòʝˤɾʛˤGƜˤƓŝĮ˙ƛˤíđƙƙƓçũĦƜˤƘĵˤíĵˤÊˤĎÊĮíŝŤÊĮíˤđƙˤƆĵũˤĠũŝƜˤŝŤÊĮíˤĵĮˤƆĵũŗˤĎÊĮíŝʛˤɿʛˤGƜˤçÊũĈĎƜˤĎđĭˤĵƙƙˤĈũÊŗíˤƛĎÊƜˤŝŔÊçòˤŝĭòĦĦòíˤĵƙˤŝòÊŗòíˤŝŤòÊģʛˤʀʛˤµĎòĮˤŝĎòˤíƓíĮ˒ƛˤĦđģòˤÊˤĈũƆˤƀĎĵˤƀÊŝˤƛŗƆđĮĈˤƘĵˤŔƓçģˤĎòŗˤũŔʜˤŝĎòˤŝŤÊŗŤòíˤũŝđĮĈˤŝƓĈĮˤĦÊĮĈũÊĈòʛˤʁʛˤ)ÊçĎˤŔòŗŝĵĮˤƀĎĵˤģĮĵƀŝˤƆĵũˤĎÊŝˤÊˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮˤĵƙˤƀĎĵˤƆĵũˤÊŗòʛˤˤɾʛˤGĮƜŗĵíũçòˤÊĮíˤòƅŔĦÊđĮˤƛĎòˤƘòçĎĮƓŖũòˤĵƙˤíĵđĮĈˤÊˤĎÊĮíŝŤÊĮíˤɿʛˤ\\x92ƀƓŤçĎˤƘĵˤÊˤŝŤĵŗƆˤÊæĵũƜˤÊĮˤÊŝƜŗĵĮÊũƜ˙ŝˤƚđŗŝƜˤƛđĭòˤđĮˤŝŔÊçòˤʀʛˤ#òŝçŗđæòˤÊˤŝƓƜũÊƜƓĵĮˤƀĎòŗòˤÊˤƀĵĭÊĮˤũŝòŝˤŝƓĈĮˤĦÊĮĈũÊĈòˤƘĵˤÊſĵƓíˤũĮƀÊĮŤòíˤÊƜŤòĮƜƓĵĮˤʁʛˤ\\x9aĎòˤƚđĮÊĦˤŔÊŗÊĈŗÊŔĎˤòƅŔĦÊđĮŝˤĎĵƀˤòſòŗƆĵĮòˤĎÊŝˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮŝˤĵƙˤĵƜĎòŗŝɾʛˤGĮƜŗĵíũçƜƓĵĮˤƘĵˤÊĮˤũĮũŝũÊĦˤŝòĦƙˊĎòĦŔˤæĵĵģʜˤĭòĮƜƓĵĮđĮĈˤÊˤĎÊĮíŝŤÊĮíˤÊŝˤÊˤĭòŤÊŔĎĵŗˤƗĵŗˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʛˤɿʛˤ#ƓŝçũŝŝˤƛĎòˤũĮòƅŔòçŤòíˤƛĎđĮĈŝˤĦòÊŗĮòíˤƚŗĵĭˤÊŝƜŗĵĮÊũŤŝʜˤđĮçĦũíđĮĈˤƛĎòˤŝĭòĦĦˤĵƙˤŝŔÊçòʛˤʀʛˤ#òŝçŗđæòˤÊˤƀĵĭÊĮ˙ŝˤçĦòſòŗˤƘÊçƜƓçˤƗĵŗˤÊſĵƓíđĮĈˤũĮƀÊĮŤòíˤÊƜŤòĮƜƓĵĮˤÊƜˤÊˤæÊŗʛˤʁʛˤ\\x1dĵĮŤòĭŔĦÊŤòˤĎĵƀˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮŝˤĵƙˤĵĮòŝòĦƙˤçÊĮˤŝĎÊŔòˤĵĮò˙ŝˤƓíòĮƜƓŤƆʛʱÊʲˤGĮŔũƜʱæʲˤ\\x89ĦÊĮŝʱʀˤĭĵŗòˤĵĭƓƜŤòíʲʱçʲˤ´ĵŤòŝ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝʟˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛʱɽʫʂˤſĵŤòŝʲ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝʟˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝʟˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝʟˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛʱʀʫʂˤſĵŤòŝʲʟɾɿGĮŔũƜ\\x89ĦÊĮˤɾ\\x89ĦÊĮˤɿʟʟ\\x89ÊŝŝÊĈòɾ\\x89ÊŝŝÊĈòɿʟʟ)L[\\x03FRORU\\x03\\x0bE\\\\\\x03<XTLDQ\\x0cµŗƓŤòˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòˤĵƙˤʁˤŝĎĵŗƜˤŔÊŗÊĈŗÊŔĎŝʛˤ\\x9aĎòˤòĮíˤŝòĮŤòĮçòˤĵƙˤòÊçĎˤŔÊŗÊĈŗÊŔĎˤĭũŝƜˤæòʝˤɾʛˤGƜˤƓŝĮ˙ƛˤíđƙƙƓçũĦƜˤƘĵˤíĵˤÊˤĎÊĮíŝŤÊĮíˤđƙˤƆĵũˤĠũŝƜˤŝŤÊĮíˤĵĮˤƆĵũŗˤĎÊĮíŝʛˤɿʛˤGƜˤçÊũĈĎƜˤĎđĭˤĵƙƙˤĈũÊŗíˤƛĎÊƜˤŝŔÊçòˤŝĭòĦĦòíˤĵƙˤŝòÊŗòíˤŝŤòÊģʛˤʀʛˤµĎòĮˤŝĎòˤíƓíĮ˒ƛˤĦđģòˤÊˤĈũƆˤƀĎĵˤƀÊŝˤƛŗƆđĮĈˤƘĵˤŔƓçģˤĎòŗˤũŔʜˤŝĎòˤŝŤÊŗŤòíˤũŝđĮĈˤŝƓĈĮˤĦÊĮĈũÊĈòʛˤʁʛˤ)ÊçĎˤŔòŗŝĵĮˤƀĎĵˤģĮĵƀŝˤƆĵũˤĎÊŝˤÊˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮˤĵƙˤƀĎĵˤƆĵũˤÊŗòʛˤˤɾʛˤGĮƜŗĵíũçòˤÊĮíˤòƅŔĦÊđĮˤƛĎòˤƘòçĎĮƓŖũòˤĵƙˤíĵđĮĈˤÊˤĎÊĮíŝŤÊĮíˤɿʛˤ\\x92ƀƓŤçĎˤƘĵˤÊˤŝŤĵŗƆˤÊæĵũƜˤÊĮˤÊŝƜŗĵĮÊũƜ˙ŝˤƚđŗŝƜˤƛđĭòˤđĮˤŝŔÊçòˤʀʛˤ#òŝçŗđæòˤÊˤŝƓƜũÊƜƓĵĮˤƀĎòŗòˤÊˤƀĵĭÊĮˤũŝòŝˤŝƓĈĮˤĦÊĮĈũÊĈòˤƘĵˤÊſĵƓíˤũĮƀÊĮŤòíˤÊƜŤòĮƜƓĵĮˤʁʛˤ\\x9aĎòˤƚđĮÊĦˤŔÊŗÊĈŗÊŔĎˤòƅŔĦÊđĮŝˤĎĵƀˤòſòŗƆĵĮòˤĎÊŝˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮŝˤĵƙˤĵƜĎòŗŝɾʛˤGĮƜŗĵíũçƜƓĵĮˤƘĵˤÊĮˤũĮũŝũÊĦˤŝòĦƙˊĎòĦŔˤæĵĵģʜˤĭòĮƜƓĵĮđĮĈˤÊˤĎÊĮíŝŤÊĮíˤÊŝˤÊˤĭòŤÊŔĎĵŗˤƗĵŗˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʛˤɿʛˤ#ƓŝçũŝŝˤƛĎòˤũĮòƅŔòçŤòíˤƛĎđĮĈŝˤĦòÊŗĮòíˤƚŗĵĭˤÊŝƜŗĵĮÊũŤŝʜˤđĮçĦũíđĮĈˤƛĎòˤŝĭòĦĦˤĵƙˤŝŔÊçòʛˤʀʛˤ#òŝçŗđæòˤÊˤƀĵĭÊĮ˙ŝˤçĦòſòŗˤƘÊçƜƓçˤƗĵŗˤÊſĵƓíđĮĈˤũĮƀÊĮŤòíˤÊƜŤòĮƜƓĵĮˤÊƜˤÊˤæÊŗʛˤʁʛˤ\\x1dĵĮŤòĭŔĦÊŤòˤĎĵƀˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮŝˤĵƙˤĵĮòŝòĦƙˤçÊĮˤŝĎÊŔòˤĵĮò˙ŝˤƓíòĮƜƓŤƆʛʱÊʲˤGĮŔũƜʱæʲˤ\\x89ĦÊĮŝʱçʲˤ´ĵŤòŝ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛGĮŔũƜ\\x89ĦÊĮˤɾˤ\\x89ĦÊĮˤɿˤˤʟʟ\\x89ÊŝŝÊĈòɾ\\x89ÊŝŝÊĈòɿʟʟɽʫʂˤſĵŤòŝ\\x89ĦÊĮˤɾˤˤˤʟʛʟʛɾʟʛɿʟʟʀʫʂˤſĵŤòŝ\\x89ĦÊĮˤʀˁʂˤˤˤ8VH\\x03UHG\\x12JUHHQ\\x03WR\\x03VKRZ\\x03ILQDO\\x03FKRLFH\\nĮʫʂˤſĵŤòŝ\\x89ĦÊĮˤɿˤˤˤ\\n\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛFigure 4: A step of deliberate search in a randomly picked Creative Writing task. Given the input, the\\nLM samples 5 different plans, then votes 5 times to decide which plan is best. The majority choice is\\nused to consequently write the output passage with the same sample-vote procedure.\\nIO CoT ToT IO\\n+refineToT\\n+refine468\\n(a) GPT-4 coherency scores\\nCoT > ToT Similar ToT > CoT010203040\\n213841(b) Human coherency comparison\\nFigure 5: Creative Writing results.Method Success Rate (%)\\nLetter Word Game\\nIO 38.7 14 0\\nCoT 40.6 15.6 1\\nToT (ours) 78 60 20\\n+best state 82.4 67.5 35\\n-prune 65.4 41.5 5\\n-backtrack 54.6 20 5\\nTable 3: Mini Crosswords results.\\nit improves IO coherency score from 6.19 to 7.67, and ToT coherency score from 7.56 to 7.91. We\\nbelieve it could be thought of as a third approach to thought generation in the ToT framework, where\\nnew thoughts can arise from refining old thoughts instead of i.i.d. or sequentially generated.\\n4.3 Mini crosswords\\nIn Game of 24 and Creative Writing, ToT is relatively shallow — at most 3 thought steps are needed\\nto reach the final output. Here we explore 5×5mini crosswords as a harder search problem involving\\nnatural language. Again, the goal is not just to solve the task, as more general crosswords can be\\nreadily solved with specialized NLP pipelines [ 34] that leverages large-scale retrieval instead of LM.\\nRather, we aim to explore the limit of LM as a general problem solver that explores its own thoughts\\nand guides its own exploration with deliberate reasoning as heuristics.\\nTask setup. We scrape data from GooBix, which contains 156 games of 5×5mini crosswords. As\\nwe observe adjacent games contain similar clues, we use 20 games with indices 1,6,···,91,96for\\ntesting, and games 136,141,146,151,156for prompting. For each task, the input describes the 5\\nhorizontal clues and 5 vertical clues, and the output should be a board of 5×5 = 25 letters to solve\\nthe crosswords. For evaluation, we consider three levels of success: the portion of correct letters (25\\nper game), words (10 per game), and games.\\nBaselines. We provide 5 example input-output pairs in the IO prompt, and in the CoT prompt\\nadditionally include intermediate words in the order h1..5 then v1..5. We run each prompt for 10\\nsamples and average the results.\\nToT setup. We leverage a depth-first search (Algorithm 2) that keeps exploring the most promising\\nsubsequent word clue until the state is no longer promising, then backtrack to the parent state to\\nexplore alternative thoughts. To make search tractable, subsequent thoughts are constrained not to\\nchange any filled words or letters, so that the ToT has at most 10 intermediate steps. For thought\\ngeneration, at each state we translate all existing thoughts (e.g. “h2.motor; h1.tasks” for the state\\nin Figure 6(a)) into letter constraints for remaining clues (e.g. “v1.To heap: tm ;...”) and prompt\\na proposal prompt 5times to come up with candidates for where and what to fill in the next word.\\nImportantly, we also prompt the LM to give a confidence level for different thoughts, and aggregate\\n7', metadata={'source': 'tree_of_thought.pdf', 'page': 6}),\n",
       " Document(page_content='>\\x0b\\nY\\x16\\x11\\x03HORSH\\n\\x0f\\x03\\x16\\x11\\x15\\x0c\\x0f\\x03\\x0b\\nK\\x15\\x11\\x03YDOXH\\n\\x0f\\x03\\x15\\x11\\x13\\x0c\\x0f\\x03\\x0b\\nK\\x14\\x11\\x03SDUFK\\n\\x0f\\x03\\x14\\x11\\x1c\\x0c\\x0f\\x03\\x0b\\nY\\x18\\x11\\x03FRYHW\\n\\x0f\\x03\\x13\\x11\\x19\\x13\\x13\\x13\\x13\\x13\\x13\\x13\\x13\\x13\\x13\\x13\\x13\\x13\\x13\\x14\\x0c\\x0f\\x03\\x0b\\nK\\x15\\x11\\x03PHULW\\n\\x0f\\x03\\x13\\x11\\x17\\x0c\\x0f\\x03\\x0b\\nY\\x14\\x11\\x03DOORZ\\n\\x0f\\x03\\x13\\x11\\x15\\x0c\\x0f\\x03\\x0b\\nY\\x15\\x11\\x03JULQG\\n\\x0f\\x03\\x13\\x11\\x14\\x0c\\x0f\\x03\\x0b\\nK\\x17\\x11\\x03OHSHU\\n\\x0f\\x03\\x13\\x11\\x14\\x0c@\\nY\\x16\\x11\\x03HORSH\\n0XOWLSOH\\x03UXQV3DUVH\\x0f\\x03ILOWHU\\x03RXW\\x03QRQ\\x10ILYH\\x10OHWWHU\\x0f\\x03VFRUH\\x0f\\x03DJJUHJDWH\\n&KRRVH\\x03\\x0bVRIW\\x03VHOI\\x10FRQVLVWHQF\\\\\"\\x0c\\x14\\x110D[\\x15\\x110D[\\x03ZLWKRXW\\x03YLRODWH\\x16\\x11\\')6\\nGĮŔũƜˤ\\x1dĦũòŝĎɿʛĭĵŤĵŗĎɾʛƘÊŝģŝĎʁʛŝÊĦĵĮƘÊŝģŝƘÊŝģŝ\\nĎʁʛˤŝÊĦĵĮˤʱŝũŗòʲſʂʛˤŝŗíŗƆˤʱĦĵƀʲſʀʛˤŝƜŗđĮĈˤʱĎƓĈĎʲʟʟ7KRXJKW\\x033URSRVDOVÊĈĈŗòĈÊŤòſʀʛˤ\\x89ŗòŤòĮƜƓĵũŝʞˤƚĦĵƀòŗƆʝˤˈˈˈˈˈˤŝũŗò6WDWH\\x03(YDOXDWRU\\x03\\x0bRYHU\\x03HDFK\\x03FOXH\\x0cſɾʛˤÉĵˤĎòÊŔʝˤƛĭˈŝˈˤʳʛʛʛʴˤđĭŔĵŝŝđæĦòſʂʛˤ#òŝƓççÊŤĵŗʞˤĭĵŗòˤíŗƆʝˤŝŗˈĮˈˤʳʛʛʛʴˤĭÊƆæòʟʟʱæÊçģƜŗÊçģʲĎʀʛĈŗÊĮíʟʟʱŝũæƜŗòòˤŔŗũĮòíʲĎʁʛˤŝÊĦĵĮĎʀʛˤĈŗÊĮíſʀʛˤŝƜŗđĮĈʟʟ\\')6\\x032UGHUĎʁʛˤŝÊĦĵĮˤʱŝũŗòʲſʂʛˤŝŗíŗƆˤʱĦĵƀʲſʀʛˤŝƜŗđĮĈˤʱĎƓĈĎʲʟʟ7KRXJKW\\x033URSRVDOVĎʁʛˤŝÊĦĵĮˤʱŝũŗòʲſʂʛˤŝŗíŗƆˤʱĦĵƀʲſʀʛˤŝƜŗđĮĈˤʱĎƓĈĎʲʟʟ7KRXJKW\\x033URSRVDOVĎʁʛˤŝÊĦĵĮˤʱŝũŗòʲſʂʛˤŝŗíŗƆˤʱĦĵƀʲſʀʛˤŝƜŗđĮĈˤʱĎƓĈĎʲʟʟ7KRXJKW\\x033URSRVDOVĎʁʛˤŝÊĦĵĮˤʱŝũŗòʲſʂʛˤŝŗíŗƆˤʱĦĵƀʲſʀʛˤŝƜŗđĮĈˤʱĎƓĈĎʲʟʟ7KRXJKW\\x033URSRVDOVʱÊʲʱæʲƛˤÊˤŝˤģˤŝĭˤĵˤƛˤĵˤŗˈˤˈˤˈˤˈˤˈŝˤÊˤĦˤĵˤĮˈˤˈˤˈˤˈˤˈFigure 6: In Mini Crosswords, (a) how thoughts are proposed and aggregated in a priority queue\\nfor depth-first search (DFS), and (b) how a state is evaluated based on the possibility of filling in\\neach remaining word clue, and pruned if any remaining clue is deemed not possible to fill by the LM.\\nThen DFS backtracks to the parent state and explore the next promising thought for clue.\\nthese across proposals to obtain a sorted list of next thoughts to explore (Figure 6(a)). For state\\nevaluations, we similarly translate each state into letter constraints for remaining clues, then evaluate\\nfor each clue if it is possible to fill given the constraints. If any remaining clue is deemed “impossible”\\nto fill in (e.g. “v1. To heap: tm s”), then the exploration of the state’s subtree is pruned and DFS\\nbacktracks to its parent to explore the next promising thought. We limit DFS search steps to 100, and\\nsimply render the deepest explored state (the first explored one if multiple) into the final output.\\nResults. As shown in Table 3, IO and CoT prompting methods perform poorly with a word-level\\nsuccess rate less than 16%, while ToT significantly improves all metrics, achieving a word-level\\nsuccess rate of 60% and solving 4 out of 20 games. Such an improvement is not surprising, given IO\\nand CoT lack mechanisms to try different clues, make changes to decisions, or backtrack.\\nOracle and ablation studies. When outputting from the oracle best DFS state (instead of the\\nheuristically determined best state) per task, ToT performance is even higher and actually solves\\n7/20 games (Table 3, “+best state”), indicating our simple output heuristics can be readily improved.\\nInterestingly, sometimes when the crosswords game is actually solved, the state evaluator might still\\ndeem some words as “impossible” and prune — possibly because 5×5crosswords by design have\\nsome rare or obselete words that GPT-4 cannot recognize2. Given the state evaluation as a pruning\\nheuristic is imperfect, we also explore ablating the pruning, and find the performance generally worse\\n(Table 3, “-prune”). However, it could actually find the correct solution for 4/20 games (though only\\noutputting 1 via heuristic), 3 of which are games ToT+pruning cannot solve within 100 steps. Thus,\\nbetter heuristics for DFS pruning are critical for problem solving in this case. Lastly, we confirm the\\nimportance of backtracking by running an ablation that keeps filling the most promising clue for at\\nmost 20 steps, allowing overwrites. This is similar to a “greedy” BFS search with breadth limit of\\nb= 1, and performs poorly with a word level success of only 20% (Table 3, “-backtrack”).\\n5 Related Work\\nPlanning and decision making. Smart planning and decision making are critical to achieving\\npredefined goals. As they are trained on vast amount of world knowledge and human examples, LMs\\nare known to have already absorbed rich commonsense that makes it possible to propose reasonable\\nplans conditioned on problem setting and environmental states [ 12,42,37,13,35,41,40]. Our\\nproposed ToT approach extends existing planning formulations by considering multiple potentially\\nfeasible plans simultaneously at each problem-solving step, and proceeding with the most promising\\nones. The integration between thought sampling and value feedback organically integrates planning\\nand decision-making mechanisms, enabling effective search inside a solution tree. On the other hand,\\ntraditional decision-making procedures usually require training dedicated reward and policy models\\nas in reinforcement learning (for example CHAI [ 33]), whereas we use the LM itself to provide\\nthe value estimates for decision making. RAP [ 9] is a concurrent work that treats language model\\n2For example, “agend” is an obsolete form of “agendum”, but GPT-4 deems it a typo for “agenda”. External\\nretrieval or web interaction could augment LM for problem solving under knowledge uncertainty.\\n8', metadata={'source': 'tree_of_thought.pdf', 'page': 7}),\n",
       " Document(page_content='reasoning as planning with its internal world model, and proposes a MCTS-based method similar to\\nToT. However, its tasks are simpler than ours, and its framework lacks the modularity to incorporate\\ndifferent tree search algorithms.\\nSelf-reflection. Using LLMs to assess the viability of their own predictions is becoming an in-\\ncreasingly important procedure in problem solving. [ 28,20,24] introduced the “self-reflection”\\nmechanism, in which LMs provide feedback to their generation candidates. [ 4] improves LMs code\\ngeneration accuracy by injecting feedback messages generated by the LM itself based on its code\\nexecution results. Similarly, [ 17] also introduces “critic” or review steps over the actions and states,\\ndeciding the next action to take in solving computer operation tasks. Another recent work very\\nrelevant to ours is “self-eval guided decoding” [ 39]. Similar to our method, self-eval decoding\\nalso follows a tree-search procedure with leaves sampled from stochastic beam search decoding,\\nwhich are then evaluated by LLM itself with carefully prepared self-eval prompts. Their approach\\nhowever, uses the PAL formulation [ 8] which represents thoughts as codes, which makes it difficult\\nto tackle challenging tasks like creative writing which we consider in this paper. Our Tree-of-Thought\\nformulation is thus more versatile and handles challenging tasks on which GPT-4 only achieves very\\nlow accuracy with standard prompts.\\nProgram-guided LLM generation. Our proposal is also related to recent advancements that organize\\nLM’s behavior with systematic procedures [ 14,44,6,43] or symbolic program guidance. For example,\\nSchlag et al. [27] embeds LMs in an algorithmic search procedure to help solve problems like question\\nanswering step-by-step, in which the search trees are expanded by relevant paragraphs that might\\nprovide answers. This approach however differs from ours in that trees are expanded by sampling\\nexternal paragraphs instead of the LM’s own thoughts, and there is no reflection or voting steps.\\nAnother approach, LLM+P [ 18], goes one step further and delegates the actual planning process to a\\nclassical planner.\\nClassical search methods. Last but not least, our approach can be treated as a modern rendition\\nof classical search methods for problem solving. For example it can be considered as a heuristic\\nsearch algorithm like A* [ 10], in which the heuristic at each search node is provided by the LM’s self-\\nassessment. From this perspective, our method is also related to NeuroLogic A*esque decoding [ 19],\\nwhich is inspired by A* search but introduces look-ahead heuristics that are efficient for LMs to\\nimprove the beam-search or top-k sampling decoding. This method however is constrained to\\nsentence generation tasks, whereas our framework are designed for complex, multi-step problem\\nsolving guarded by value feedback.\\n6 Discussion\\nLimitations and future directions. Deliberate search such as ToT might not be necessary for many\\nexisting tasks that GPT-4 already excels at (see Appendix B.1), and as an initial step this work only\\nexplores three relatively simple tasks that challenges GPT-4 (see Appendix B.2 for some GPT-3.5\\nexperiment results) and calls of better search and planning abilities incorporated with LMs. However,\\nas we begin to deploy LMs for more real-world decision making applications (e.g. coding, data\\nanalysis, robotics, etc.), more complex tasks could emerge and present new opportunities to study\\nthese research questions. Also, search methods like ToT requires more resources (e.g. GPT-4 API\\ncost) than sampling methods in order to improve task performances, but the modular flexibility of\\nToT allows users to customize such performance-cost tradeoffs, and ongoing open-source efforts [ 32]\\nshould readily reduce such costs in the near future. More details about cost and efficiency are in\\nAppendix B.3. Lastly, this work focuses on using an off-the-shelf LM, and fine-tuning LMs using\\na ToT-style high-level counterfactual decision making (e.g. deliberating over potential choices for\\nthe next paragraph, instead of predicting the next token) might present opportunities to enhance the\\nproblem-solving capabilities of LMs.\\nConclusion. The associative “System 1” of LMs can be beneficially augmented by a “System 2”\\nbased on searching a tree of possible paths to the solution to a problem. The Tree of Thoughts\\nframework provides a way to translate classical insights about problem-solving into actionable\\nmethods for contemporary LMs. At the same time, LMs address a weakness of these classical\\nmethods, providing a way to solve complex problems that are not easily formalized, such as creative\\nwriting. We see this intersection of LMs with classical approaches to AI as an exciting direction.\\n9', metadata={'source': 'tree_of_thought.pdf', 'page': 8}),\n",
       " Document(page_content='Broader Impact\\nToT is a framework that empowers LMs to more autonomously and intelligently make decisions\\nand solve problems. While current tasks are limited to reasoning and search problems, future\\napplications involving interaction with external environments or humans could bring potential danger,\\ne.g. facilitating harmful uses of LMs. On the other hand, ToT also improves the interpretability\\nof model decisions and the opportunity for human alignment, as the resulting representations are\\nreadable, high-level language reasoning instead of implicit, low-level token values.\\nAcknowledgements\\nSY and KN acknowledge support from an Oracle Collaborative Research award and the National\\nScience Foundation under Grant No. 2239363. Any opinions, findings, conclusions, or recommenda-\\ntions expressed in this material are those of the author(s) and do not necessarily reflect the views of\\nthe National Science Foundation. SY is also supported by the Harold W. Dodds Fellowship from\\nPrinceton.\\nReferences\\n[1]T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam,\\nG. Sastry, A. Askell, et al. Language models are few-shot learners. Advances in neural\\ninformation processing systems , 33:1877–1901, 2020.\\n[2]C. Browne, E. J. Powley, D. Whitehouse, S. M. M. Lucas, P. I. Cowling, P. Rohlfshagen,\\nS. Tavener, D. P. Liebana, S. Samothrakis, and S. Colton. A survey of monte carlo tree search\\nmethods. IEEE Transactions on Computational Intelligence and AI in Games , 4:1–43, 2012.\\n[3]M. Campbell, A. J. Hoane Jr, and F.-h. Hsu. Deep blue. Artificial intelligence , 134(1-2):57–83,\\n2002.\\n[4]X. Chen, M. Lin, N. Sch ¨arli, and D. Zhou. Teaching large language models to self-debug, 2023.\\n[5]A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W.\\nChung, C. Sutton, S. Gehrmann, et al. Palm: Scaling language modeling with pathways. arXiv\\npreprint arXiv:2204.02311 , 2022.\\n[6]A. Creswell and M. Shanahan. Faithful reasoning using large language models. arXiv preprint\\narXiv:2208.14271 , 2022.\\n[7]N. D. Daw, Y . Niv, and P. Dayan. Uncertainty-based competition between prefrontal and\\ndorsolateral striatal systems for behavioral control. Nature neuroscience , 8(12):1704–1711,\\n2005.\\n[8]L. Gao, A. Madaan, S. Zhou, U. Alon, P. Liu, Y . Yang, J. Callan, and G. Neubig. Pal: Program-\\naided language models, 2023.\\n[9]S. Hao, Y . Gu, H. Ma, J. J. Hong, Z. Wang, D. Z. Wang, and Z. Hu. Reasoning with language\\nmodel is planning with world model. arXiv preprint arXiv:2305.14992 , 2023.\\n[10] P. E. Hart, N. J. Nilsson, and B. Raphael. A formal basis for the heuristic determination of\\nminimum cost paths. IEEE Transactions on Systems Science and Cybernetics , 4(2):100–107,\\n1968. doi: 10.1109/TSSC.1968.300136.\\n[11] P. E. Hart, N. J. Nilsson, and B. Raphael. A formal basis for the heuristic determination of\\nminimum cost paths. IEEE transactions on Systems Science and Cybernetics , 4(2):100–107,\\n1968.\\n[12] W. Huang, P. Abbeel, D. Pathak, and I. Mordatch. Language models as zero-shot planners:\\nExtracting actionable knowledge for embodied agents, 2022.\\n[13] W. Huang, F. Xia, T. Xiao, H. Chan, J. Liang, P. Florence, A. Zeng, J. Tompson, I. Mordatch,\\nY . Chebotar, et al. Inner monologue: Embodied reasoning through planning with language\\nmodels. arXiv preprint arXiv:2207.05608 , 2022.\\n10', metadata={'source': 'tree_of_thought.pdf', 'page': 9}),\n",
       " Document(page_content='[14] J. Jung, L. Qin, S. Welleck, F. Brahman, C. Bhagavatula, R. L. Bras, and Y . Choi. Maieu-\\ntic prompting: Logically consistent reasoning with recursive explanations. arXiv preprint\\narXiv:2205.11822 , 2022.\\n[15] D. Kahneman. Thinking, fast and slow . Macmillan, 2011.\\n[16] D. Kahneman, S. Frederick, et al. Representativeness revisited: Attribute substitution in intuitive\\njudgment. Heuristics and biases: The psychology of intuitive judgment , 49(49-81):74, 2002.\\n[17] G. Kim, P. Baldi, and S. McAleer. Language models can solve computer tasks, 2023.\\n[18] B. Liu, Y . Jiang, X. Zhang, Q. Liu, S. Zhang, J. Biswas, and P. Stone. Llm+p: Empowering\\nlarge language models with optimal planning proficiency, 2023.\\n[19] X. Lu, S. Welleck, P. West, L. Jiang, J. Kasai, D. Khashabi, R. L. Bras, L. Qin, Y . Yu,\\nR. Zellers, N. A. Smith, and Y . Choi. Neurologic a*esque decoding: Constrained text generation\\nwith lookahead heuristics. In North American Chapter of the Association for Computational\\nLinguistics , 2021.\\n[20] A. Madaan, N. Tandon, P. Gupta, S. Hallinan, L. Gao, S. Wiegreffe, U. Alon, N. Dziri,\\nS. Prabhumoye, Y . Yang, S. Welleck, B. P. Majumder, S. Gupta, A. Yazdanbakhsh, and P. Clark.\\nSelf-refine: Iterative refinement with self-feedback, 2023.\\n[21] A. Newell, J. C. Shaw, and H. A. Simon. Report on a general problem solving program. In IFIP\\ncongress , volume 256, page 64. Pittsburgh, PA, 1959.\\n[22] A. Newell, H. A. Simon, et al. Human problem solving . Prentice-Hall, 1972.\\n[23] OpenAI. Gpt-4 technical report. ArXiv , abs/2303.08774, 2023.\\n[24] D. Paul, M. Ismayilzada, M. Peyrard, B. Borges, A. Bosselut, R. West, and B. Faltings. Refiner:\\nReasoning feedback on intermediate representations, 2023.\\n[25] A. Radford, K. Narasimhan, T. Salimans, I. Sutskever, et al. Improving language understanding\\nby generative pre-training. OpenAI blog , 2018.\\n[26] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are\\nunsupervised multitask learners. OpenAI blog , 1(8):9, 2019.\\n[27] I. Schlag, S. Sukhbaatar, A. Celikyilmaz, W. tau Yih, J. Weston, J. Schmidhuber, and X. Li.\\nLarge language model programs, 2023.\\n[28] N. Shinn, B. Labash, and A. Gopinath. Reflexion: an autonomous agent with dynamic memory\\nand self-reflection, 2023.\\n[29] D. Silver, J. Schrittwieser, K. Simonyan, I. Antonoglou, A. Huang, A. Guez, T. Hubert, L. Baker,\\nM. Lai, A. Bolton, et al. Mastering the game of go without human knowledge. nature , 550\\n(7676):354–359, 2017.\\n[30] S. A. Sloman. The empirical case for two systems of reasoning. Psychological bulletin , 119(1):\\n3, 1996.\\n[31] K. E. Stanovich. Who is rational? Studies of individual differences in reasoning . Psychology\\nPress, 1999.\\n[32] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozi `ere, N. Goyal,\\nE. Hambro, F. Azhar, et al. Llama: Open and efficient foundation language models. arXiv\\npreprint arXiv:2302.13971 , 2023.\\n[33] S. Verma, J. Fu, S. Yang, and S. Levine. Chai: A chatbot ai for task-oriented dialogue with\\noffline reinforcement learning. In Proceedings of the 2022 Conference of the North American\\nChapter of the Association for Computational Linguistics: Human Language Technologies ,\\npages 4471–4491, 2022.\\n11', metadata={'source': 'tree_of_thought.pdf', 'page': 10}),\n",
       " Document(page_content='[34] E. Wallace, N. Tomlin, A. Xu, K. Yang, E. Pathak, M. Ginsberg, and D. Klein. Automated\\ncrossword solving. arXiv preprint arXiv:2205.09665 , 2022.\\n[35] L. Wang, W. Xu, Y . Lan, Z. Hu, Y . Lan, R. K.-W. Lee, and E.-P. Lim. Plan-and-solve prompting:\\nImproving zero-shot chain-of-thought reasoning by large language models, 2023.\\n[36] X. Wang, J. Wei, D. Schuurmans, Q. Le, E. Chi, and D. Zhou. Self-consistency improves chain\\nof thought reasoning in language models. arXiv preprint arXiv:2203.11171 , 2022.\\n[37] Z. Wang, S. Cai, A. Liu, X. Ma, and Y . Liang. Describe, explain, plan and select: Interactive\\nplanning with large language models enables open-world multi-task agents, 2023.\\n[38] J. Wei, X. Wang, D. Schuurmans, M. Bosma, E. Chi, Q. Le, and D. Zhou. Chain of thought\\nprompting elicits reasoning in large language models. arXiv preprint arXiv:2201.11903 , 2022.\\n[39] Y . Xie, K. Kawaguchi, Y . Zhao, X. Zhao, M.-Y . Kan, J. He, and Q. Xie. Decomposition\\nenhances reasoning via self-evaluation guided decoding, 2023.\\n[40] S. Yang, O. Nachum, Y . Du, J. Wei, P. Abbeel, and D. Schuurmans. Foundation models for\\ndecision making: Problems, methods, and opportunities, 2023.\\n[41] S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. Narasimhan, and Y . Cao. ReAct: Synergizing\\nreasoning and acting in language models. arXiv preprint arXiv:2210.03629 , 2022.\\n[42] S. Zhang, Z. Chen, Y . Shen, M. Ding, J. B. Tenenbaum, and C. Gan. Planning with large\\nlanguage models for code generation. In The Eleventh International Conference on Learning\\nRepresentations , 2023. URL https://openreview.net/forum?id=Lr8cOOtYbfL .\\n[43] D. Zhou, N. Sch ¨arli, L. Hou, J. Wei, N. Scales, X. Wang, D. Schuurmans, C. Cui, O. Bousquet,\\nQ. Le, et al. Least-to-most prompting enables complex reasoning in large language models.\\narXiv preprint arXiv:2205.10625 , 2022.\\n[44] X. Zhu, J. Wang, L. Zhang, Y . Zhang, R. Gan, J. Zhang, and Y . Yang. Solving math word\\nproblem via cooperative reasoning induced language models. arXiv preprint arXiv:2210.16257 ,\\n2022.\\n12', metadata={'source': 'tree_of_thought.pdf', 'page': 11}),\n",
       " Document(page_content='A Code, Prompts, Trajectories\\nAll code is available at https://github.com/princeton-nlp/tree-of-thought-llm .\\nAll prompts are available at https://github.com/princeton-nlp/tree-of-thought-llm/\\ntree/master/src/tot/prompts .\\nTrajectories are available at https://github.com/princeton-nlp/tree-of-thought-llm/\\ntree/master/logs .\\nB Additional Experiment Results\\nGiven the motivation of exploring and extending the capability frontier of language models, our\\nexperiments in the main paper have focused on a setup with the state-of-the-art language model\\n(GPT-4), and three hard tasks invented to challenge it. Here, we report additional experiments with\\nweaker LLM or easier tasks, and discuss cost and efficiency.\\nGSM8K StrategyQA\\nIO 51 73\\nCoT 86 82\\nToT 90 83\\nTable 4: New tasks with\\nzero-shot ToT and GPT-4.GPT-4 GPT-3.5\\nIO 7.3% 6%\\nCoT 4.0% 3%\\nToT 74% 19%\\nTable 5: Game of 24 with\\nGPT-4 vs GPT-3.5.GPT-4 GPT-3.5\\nIO 6.19 4.47\\nCoT 6.93 5.16\\nToT 7.56 6.62\\nTable 6: Creative Writing with\\nGPT-4 vs. GPT-3.5.\\nB.1 Extension to new tasks (GSM8k, StrategyQA) with zero-shot ToT\\nWhile more common NLP tasks might be too easy for GPT-4 and do not require ToT (which is why\\nwe considered harder new tasks), we believe applying ToT to new tasks could be straightforward.\\nFor example, we implemented a simple and generic zero-shot ToT-BFS similar to creative writing\\n(sample 5 problem solving strategies then vote for the best one; then sample 5 solutions based on the\\nbest strategy then vote for the best one) for GSM8K and StrategyQA with few extra lines of code:\\n# define the answer format of new tasks\\ngsm8k_format = ‘\"the answer is n\" where n is a number’\\nstrategyqa_format = ‘either \"the answer is yes\" or \"the answer is no\"’\\n# define zero-shot io prompting\\nstandard_prompt = ‘Answer the following question with {format}: {input}’\\n# define thought format for zero-shot cot and zero-shot tot\\ncot_prompt = ‘‘‘Answer the following question: {input}\\nMake a strategy then write. Your output should be of the following format:\\nStrategy:\\nYour strategy about how to answer the question.\\nAnswer:\\nYour answer to the question. It should end with {format}.\\n’’’\\n# define zero-shot voting used for zero-shot tot\\nvote_prompt = ‘‘‘Given an instruction and several choices,\\ndecide which choice is most promising.\\nAnalyze each choice in detail, then conclude in the last line\\n\"The best choice is {s}\", where s the integer id of the choice.\\n’’’\\n13', metadata={'source': 'tree_of_thought.pdf', 'page': 12}),\n",
       " Document(page_content='We evaluated on a subset of 100 random GSM8K test and StrategyQA dev questions. As shown\\nin Table 4 and as expected, ToT improves over CoT on both tasks (but only slightly, given GPT-4\\n+ CoT is already very good on such tasks, and StrategyQA’s bottleneck is external knowledge, not\\nreasoning). Considering computational costs, it is more suitable to try smaller LLMs + ToT for\\ntraditional NLP tasks, or GPT-4 + ToT for hard tasks that challenge GPT-4 + CoT’s reasoning.\\nB.2 Extension to new LMs (GPT-3.5)\\nTo understand how ToT works with other LLMs, we also ran GPT-3.5-turbo for Creative Writing\\n(Table 6) and Game of 24 (Table 5). On both tasks, “ToT >CoT>IO” remains true for GPT-3.5. On\\nCreative Writing, we find GPT-3.5+ToT outperform GPT-4+IO, and similar to GPT-4+CoT, which\\nsuggests ToT could also work well on weaker language models.\\nOn Game of 24 (we changed 1-shot proposal prompt to 3-shot to make it work), GPT-3.5+ToT’s\\n19% is far worse than GPT-4+ToT’s 74%. To further understand the importance of generation\\nvs. evaluation, we ran GPT-4 generation + GPT-3.5 evaluation (64%) and GPT-3.5 generation +\\nGPT-4 evaluation (31%). This suggests the game’s bottleneck is thought generation, and different\\ngeneration/evaluation language models might attain decent results while reducing costs.\\nB.3 Cost and efficiency\\nRunning ToT requires significantly more computations than IO or CoT prompting. For example, in\\nGame of 24 (Table 7 below), solving a problem with ToT requires 5.5k completion tokens, close to\\n100 CoT trials (6.7k tokens). But the performance of ToT is better than best of 100 independent CoT\\ntrials.\\nGame of 24 Generate/Prompt tokens Cost per case Success\\nIO (best of 100) 1.8k / 1.0k $0.13 33%\\nCoT (best of 100) 6.7k / 2.2k $0.47 49%\\nToT 5.5k / 1.4k $0.74 74%\\nTable 7: Cost analysis on Game of 24.\\nOn Creative Writing (Table 8 below), we found ToT takes around 5x completion tokens and money\\ncost, which is intuitive as b= 5and most tokens are generated passages.\\nCreative Writing Generate/Prompt tokens Cost per case\\nIO 0.9k / 0.4k $0.06\\nCoT 0.9k / 0.4k $0.07\\nToT 4k / 2.9k $0.32\\nTable 8: Cost analysis on Game of 24.\\nSo completing Game of 24 and Creative Writing’s main ToT experiments cost around 0.74×100 +\\n0.32×100 = 106 dollars. Crosswords’ DFS experiments should be also within 100dollars. In\\ngeneral, cost and efficiency of ToT highly depend on the prompts and search algorithms used, and\\ncould require 5-100 times more generated tokens than CoT. Some actionable insights:\\n•We recommend using ToT on tasks requiring deliberate reasoning, on which CoT struggles.\\n•Flexibility of ToT allows some performance-cost tradeoff, e.g., change beam size or vote\\nnumber in BFS, few-shot vs. zero-shot prompting, GPT-3.5 vs. GPT-4, etc. One could\\nconfigure the setup based on some resource constraints or performance goal.\\n•There is much space for improving efficiency, e.g., BFS could early stop when solution is\\nfound, or trim down beam size to when some thoughts are ”impossible”.\\n•We believe that more computation is indeed required in order for the model to achieve\\nstronger intelligence, and this should not become a blocking issue as in the long run, (open-\\nsource) LMs will become much cheaper and more efficient. It is also a great direction how\\nto better train/finetune LMs for thought generation and/or evaluation.\\n14', metadata={'source': 'tree_of_thought.pdf', 'page': 13})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PDF Document reader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"tree_of_thought.pdf\")\n",
    "pdf_documents = loader.load()\n",
    "pdf_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Tree of Thoughts: Deliberate Problem Solving\\nwith Large Language Models\\nShunyu Yao\\nPrinceton UniversityDian Yu\\nGoogle DeepMindJeffrey Zhao\\nGoogle DeepMindIzhak Shafran\\nGoogle DeepMind\\nThomas L. Griffiths\\nPrinceton UniversityYuan Cao\\nGoogle DeepMindKarthik Narasimhan\\nPrinceton University\\nAbstract\\nLanguage models are increasingly being deployed for general problem solving\\nacross a wide range of tasks, but are still confined to token-level, left-to-right\\ndecision-making processes during inference. This means they can fall short in\\ntasks that require exploration, strategic lookahead, or where initial decisions play\\na pivotal role. To surmount these challenges, we introduce a new framework for\\nlanguage model inference, “Tree of Thoughts” (ToT), which generalizes over the\\npopular “Chain of Thought” approach to prompting language models, and enables\\nexploration over coherent units of text (“thoughts”) that serve as intermediate steps', metadata={'source': 'tree_of_thought.pdf', 'page': 0}),\n",
       " Document(page_content='popular “Chain of Thought” approach to prompting language models, and enables\\nexploration over coherent units of text (“thoughts”) that serve as intermediate steps\\ntoward problem solving. ToT allows LMs to perform deliberate decision making\\nby considering multiple different reasoning paths and self-evaluating choices to\\ndecide the next course of action, as well as looking ahead or backtracking when\\nnecessary to make global choices. Our experiments show that ToT significantly\\nenhances language models’ problem-solving abilities on three novel tasks requiring\\nnon-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords.\\nFor instance, in Game of 24, while GPT-4 with chain-of-thought prompting only\\nsolved 4% of tasks, our method achieved a success rate of 74%. Code repo with all\\nprompts: https://github.com/princeton-nlp/tree-of-thought-llm .\\n1 Introduction\\nOriginally designed to generate text, scaled-up versions of language models (LMs) such as GPT [ 25,', metadata={'source': 'tree_of_thought.pdf', 'page': 0}),\n",
       " Document(page_content='prompts: https://github.com/princeton-nlp/tree-of-thought-llm .\\n1 Introduction\\nOriginally designed to generate text, scaled-up versions of language models (LMs) such as GPT [ 25,\\n26,1,23] and PaLM [ 5] have been shown to be increasingly capable of performing an ever wider\\nrange of tasks requiring mathematical, symbolic, commonsense, and knowledge reasoning. It is\\nperhaps surprising that underlying all this progress is still the original autoregressive mechanism for\\ngenerating text, which makes token-level decisions one by one and in a left-to-right fashion. Is such\\na simple mechanism sufficient for a LM to be built toward a general problem solver? If not, what\\nproblems would challenge the current paradigm, and what should be alternative mechanisms?\\nThe literature on human cognition provides some clues to answer these questions. Research on “dual\\nprocess” models suggests that people have two modes in which they engage with decisions – a fast,', metadata={'source': 'tree_of_thought.pdf', 'page': 0}),\n",
       " Document(page_content='The literature on human cognition provides some clues to answer these questions. Research on “dual\\nprocess” models suggests that people have two modes in which they engage with decisions – a fast,\\nautomatic, unconscious mode (“System 1”) and a slow, deliberate, conscious mode (“System 2”)\\n[30,31,16,15]. These two modes have previously been connected to a variety of mathematical\\nmodels used in machine learning. For example, research on reinforcement learning in humans and\\nother animals has explored the circumstances under which they engage in associative “model free”\\nlearning or more deliberative “model based” planning [ 7]. The simple associative token-level choices\\nof LMs are also reminiscent of “System 1”, and thus might benefit from augmentation by a more\\ndeliberate “System 2” planning process that (1) maintains and explores diverse alternatives for current\\n37th Conference on Neural Information Processing Systems (NeurIPS 2023).arXiv:2305.10601v2  [cs.CL]  3 Dec 2023', metadata={'source': 'tree_of_thought.pdf', 'page': 0}),\n",
       " Document(page_content='GĮŔũƜ\\njũƜŔũƜGĮŔũƜ\\njũƜŔũƜʱÊʲˤGjʱæʲˤ\\x1dĵÉGĮŔũƜ\\nˤjũƜŔũƜʱçʲˤ\\x1dĵÉˁ\\x92\\x1dʟʟʟʟaÊĠĵŗƓŤƆˤſĵŤòGĮŔũƜ\\nˤjũƜŔũƜʱíʲˤÉĵÉˤʱĵũŗŝʲʟʟʟʟʟʟˤˤʝˤƛĎĵũĈĎƜ)L[\\x03FRORU\\x03\\x0bE\\\\\\x03<XTLDQ\\x0c0DUN\\x03GLIIHUHQFH\\x03E\\\\\\x03FRORU\\nGĮŔũƜ\\njũƜŔũƜGĮŔũƜ\\njũƜŔũƜGĮŔũƜ\\nˤjũƜŔũƜʱçʲˤ\\x92òĦƙˤ\\x1dĵĮŝƓŝŤòĮçƆˤƀƓƜĎˤ\\x1dĵÉˤʱ\\x1dĵÉˁ\\x92\\x1dʲaÊĠĵŗƓŤƆˤſĵŤòGĮŔũƜ\\nˤjũƜŔũƜʱíʲˤÉŗòòˤĵƙˤ\\x9aĎĵũĈĎŤŝˤʱÉĵÉʲʟʟʟʟʟʟʟʟʟʟˤˤƛĎĵũĈĎƜ\\nʱçʲˤ\\x1dĎÊđĮˤĵƙˤ\\x9aĎĵũĈĎƜˤ\\x89ŗĵĭŔƜđĮĈˤʱ\\x1dĵÉʲʱÊʲˤGĮŔũƜˁjũƜŔũƜˤ\\x89ŗĵĭŔƜđĮĈˤʱGjʲFigure 1: Schematic illustrating various approaches to problem solving with LLMs. Each rectangle\\nbox represents a thought , which is a coherent language sequence that serves as an intermediate\\nstep toward problem solving. See concrete examples of how thoughts are generated, evaluated, and\\nsearched in Figures 2,4,6.\\nchoices instead of just picking one, and (2) evaluates its current status and actively looks ahead or\\nbacktracks to make more global decisions.\\nTo design such a planning process, we return to the origins of artificial intelligence (and cognitive', metadata={'source': 'tree_of_thought.pdf', 'page': 1})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "documents = text_splitter.split_documents(pdf_documents)\n",
    "documents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chroma Vector Embeddings and Vesctor Store\n",
    "from langchain_community.vectorstores import Chroma\n",
    "db = Chroma.from_documents(pdf_documents[:30], embedding=embeddings) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='µŗƓŤòˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòˤĵƙˤʁˤŝĎĵŗƜˤŔÊŗÊĈŗÊŔĎŝʛˤ\\x9aĎòˤòĮíˤŝòĮŤòĮçòˤĵƙˤòÊçĎˤŔÊŗÊĈŗÊŔĎˤĭũŝƜˤæòʝˤɾʛˤGƜˤƓŝĮ˙ƛˤíđƙƙƓçũĦƜˤƘĵˤíĵˤÊˤĎÊĮíŝŤÊĮíˤđƙˤƆĵũˤĠũŝƜˤŝŤÊĮíˤĵĮˤƆĵũŗˤĎÊĮíŝʛˤɿʛˤGƜˤçÊũĈĎƜˤĎđĭˤĵƙƙˤĈũÊŗíˤƛĎÊƜˤŝŔÊçòˤŝĭòĦĦòíˤĵƙˤŝòÊŗòíˤŝŤòÊģʛˤʀʛˤµĎòĮˤŝĎòˤíƓíĮ˒ƛˤĦđģòˤÊˤĈũƆˤƀĎĵˤƀÊŝˤƛŗƆđĮĈˤƘĵˤŔƓçģˤĎòŗˤũŔʜˤŝĎòˤŝŤÊŗŤòíˤũŝđĮĈˤŝƓĈĮˤĦÊĮĈũÊĈòʛˤʁʛˤ)ÊçĎˤŔòŗŝĵĮˤƀĎĵˤģĮĵƀŝˤƆĵũˤĎÊŝˤÊˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮˤĵƙˤƀĎĵˤƆĵũˤÊŗòʛˤˤɾʛˤGĮƜŗĵíũçòˤÊĮíˤòƅŔĦÊđĮˤƛĎòˤƘòçĎĮƓŖũòˤĵƙˤíĵđĮĈˤÊˤĎÊĮíŝŤÊĮíˤɿʛˤ\\x92ƀƓŤçĎˤƘĵˤÊˤŝŤĵŗƆˤÊæĵũƜˤÊĮˤÊŝƜŗĵĮÊũƜ˙ŝˤƚđŗŝƜˤƛđĭòˤđĮˤŝŔÊçòˤʀʛˤ#òŝçŗđæòˤÊˤŝƓƜũÊƜƓĵĮˤƀĎòŗòˤÊˤƀĵĭÊĮˤũŝòŝˤŝƓĈĮˤĦÊĮĈũÊĈòˤƘĵˤÊſĵƓíˤũĮƀÊĮŤòíˤÊƜŤòĮƜƓĵĮˤʁʛˤ\\x9aĎòˤƚđĮÊĦˤŔÊŗÊĈŗÊŔĎˤòƅŔĦÊđĮŝˤĎĵƀˤòſòŗƆĵĮòˤĎÊŝˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮŝˤĵƙˤĵƜĎòŗŝɾʛˤGĮƜŗĵíũçƜƓĵĮˤƘĵˤÊĮˤũĮũŝũÊĦˤŝòĦƙˊĎòĦŔˤæĵĵģʜˤĭòĮƜƓĵĮđĮĈˤÊˤĎÊĮíŝŤÊĮíˤÊŝˤÊˤĭòŤÊŔĎĵŗˤƗĵŗˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʛˤɿʛˤ#ƓŝçũŝŝˤƛĎòˤũĮòƅŔòçŤòíˤƛĎđĮĈŝˤĦòÊŗĮòíˤƚŗĵĭˤÊŝƜŗĵĮÊũŤŝʜˤđĮçĦũíđĮĈˤƛĎòˤŝĭòĦĦˤĵƙˤŝŔÊçòʛˤʀʛˤ#òŝçŗđæòˤÊˤƀĵĭÊĮ˙ŝˤçĦòſòŗˤƘÊçƜƓçˤƗĵŗˤÊſĵƓíđĮĈˤũĮƀÊĮŤòíˤÊƜŤòĮƜƓĵĮˤÊƜˤÊˤæÊŗʛˤʁʛˤ\\x1dĵĮŤòĭŔĦÊŤòˤĎĵƀˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮŝˤĵƙˤĵĮòŝòĦƙˤçÊĮˤŝĎÊŔòˤĵĮò˙ŝˤƓíòĮƜƓŤƆʛʱÊʲˤGĮŔũƜʱæʲˤ\\x89ĦÊĮŝʱʀˤĭĵŗòˤĵĭƓƜŤòíʲʱçʲˤ´ĵŤòŝ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝʟˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛʱɽʫʂˤſĵŤòŝʲ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝʟˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝʟˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝʟˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛʱʀʫʂˤſĵŤòŝʲʟɾɿGĮŔũƜ\\x89ĦÊĮˤɾ\\x89ĦÊĮˤɿʟʟ\\x89ÊŝŝÊĈòɾ\\x89ÊŝŝÊĈòɿʟʟ)L[\\x03FRORU\\x03\\x0bE\\\\\\x03<XTLDQ\\x0cµŗƓŤòˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòˤĵƙˤʁˤŝĎĵŗƜˤŔÊŗÊĈŗÊŔĎŝʛˤ\\x9aĎòˤòĮíˤŝòĮŤòĮçòˤĵƙˤòÊçĎˤŔÊŗÊĈŗÊŔĎˤĭũŝƜˤæòʝˤɾʛˤGƜˤƓŝĮ˙ƛˤíđƙƙƓçũĦƜˤƘĵˤíĵˤÊˤĎÊĮíŝŤÊĮíˤđƙˤƆĵũˤĠũŝƜˤŝŤÊĮíˤĵĮˤƆĵũŗˤĎÊĮíŝʛˤɿʛˤGƜˤçÊũĈĎƜˤĎđĭˤĵƙƙˤĈũÊŗíˤƛĎÊƜˤŝŔÊçòˤŝĭòĦĦòíˤĵƙˤŝòÊŗòíˤŝŤòÊģʛˤʀʛˤµĎòĮˤŝĎòˤíƓíĮ˒ƛˤĦđģòˤÊˤĈũƆˤƀĎĵˤƀÊŝˤƛŗƆđĮĈˤƘĵˤŔƓçģˤĎòŗˤũŔʜˤŝĎòˤŝŤÊŗŤòíˤũŝđĮĈˤŝƓĈĮˤĦÊĮĈũÊĈòʛˤʁʛˤ)ÊçĎˤŔòŗŝĵĮˤƀĎĵˤģĮĵƀŝˤƆĵũˤĎÊŝˤÊˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮˤĵƙˤƀĎĵˤƆĵũˤÊŗòʛˤˤɾʛˤGĮƜŗĵíũçòˤÊĮíˤòƅŔĦÊđĮˤƛĎòˤƘòçĎĮƓŖũòˤĵƙˤíĵđĮĈˤÊˤĎÊĮíŝŤÊĮíˤɿʛˤ\\x92ƀƓŤçĎˤƘĵˤÊˤŝŤĵŗƆˤÊæĵũƜˤÊĮˤÊŝƜŗĵĮÊũƜ˙ŝˤƚđŗŝƜˤƛđĭòˤđĮˤŝŔÊçòˤʀʛˤ#òŝçŗđæòˤÊˤŝƓƜũÊƜƓĵĮˤƀĎòŗòˤÊˤƀĵĭÊĮˤũŝòŝˤŝƓĈĮˤĦÊĮĈũÊĈòˤƘĵˤÊſĵƓíˤũĮƀÊĮŤòíˤÊƜŤòĮƜƓĵĮˤʁʛˤ\\x9aĎòˤƚđĮÊĦˤŔÊŗÊĈŗÊŔĎˤòƅŔĦÊđĮŝˤĎĵƀˤòſòŗƆĵĮòˤĎÊŝˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮŝˤĵƙˤĵƜĎòŗŝɾʛˤGĮƜŗĵíũçƜƓĵĮˤƘĵˤÊĮˤũĮũŝũÊĦˤŝòĦƙˊĎòĦŔˤæĵĵģʜˤĭòĮƜƓĵĮđĮĈˤÊˤĎÊĮíŝŤÊĮíˤÊŝˤÊˤĭòŤÊŔĎĵŗˤƗĵŗˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʛˤɿʛˤ#ƓŝçũŝŝˤƛĎòˤũĮòƅŔòçŤòíˤƛĎđĮĈŝˤĦòÊŗĮòíˤƚŗĵĭˤÊŝƜŗĵĮÊũŤŝʜˤđĮçĦũíđĮĈˤƛĎòˤŝĭòĦĦˤĵƙˤŝŔÊçòʛˤʀʛˤ#òŝçŗđæòˤÊˤƀĵĭÊĮ˙ŝˤçĦòſòŗˤƘÊçƜƓçˤƗĵŗˤÊſĵƓíđĮĈˤũĮƀÊĮŤòíˤÊƜŤòĮƜƓĵĮˤÊƜˤÊˤæÊŗʛˤʁʛˤ\\x1dĵĮŤòĭŔĦÊŤòˤĎĵƀˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮŝˤĵƙˤĵĮòŝòĦƙˤçÊĮˤŝĎÊŔòˤĵĮò˙ŝˤƓíòĮƜƓŤƆʛʱÊʲˤGĮŔũƜʱæʲˤ\\x89ĦÊĮŝʱçʲˤ´ĵŤòŝ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛGĮŔũƜ\\x89ĦÊĮˤɾˤ\\x89ĦÊĮˤɿˤˤʟʟ\\x89ÊŝŝÊĈòɾ\\x89ÊŝŝÊĈòɿʟʟɽʫʂˤſĵŤòŝ\\x89ĦÊĮˤɾˤˤˤʟʛʟʛɾʟʛɿʟʟʀʫʂˤſĵŤòŝ\\x89ĦÊĮˤʀˁʂˤˤˤ8VH\\x03UHG\\x12JUHHQ\\x03WR\\x03VKRZ\\x03ILQDO\\x03FKRLFH\\nĮʫʂˤſĵŤòŝ\\x89ĦÊĮˤɿˤˤˤ\\n\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛFigure 4: A step of deliberate search in a randomly picked Creative Writing task. Given the input, the\\nLM samples 5 different plans, then votes 5 times to decide which plan is best. The majority choice is\\nused to consequently write the output passage with the same sample-vote procedure.\\nIO CoT ToT IO\\n+refineToT\\n+refine468\\n(a) GPT-4 coherency scores\\nCoT > ToT Similar ToT > CoT010203040\\n213841(b) Human coherency comparison\\nFigure 5: Creative Writing results.Method Success Rate (%)\\nLetter Word Game\\nIO 38.7 14 0\\nCoT 40.6 15.6 1\\nToT (ours) 78 60 20\\n+best state 82.4 67.5 35\\n-prune 65.4 41.5 5\\n-backtrack 54.6 20 5\\nTable 3: Mini Crosswords results.\\nit improves IO coherency score from 6.19 to 7.67, and ToT coherency score from 7.56 to 7.91. We\\nbelieve it could be thought of as a third approach to thought generation in the ToT framework, where\\nnew thoughts can arise from refining old thoughts instead of i.i.d. or sequentially generated.\\n4.3 Mini crosswords\\nIn Game of 24 and Creative Writing, ToT is relatively shallow — at most 3 thought steps are needed\\nto reach the final output. Here we explore 5×5mini crosswords as a harder search problem involving\\nnatural language. Again, the goal is not just to solve the task, as more general crosswords can be\\nreadily solved with specialized NLP pipelines [ 34] that leverages large-scale retrieval instead of LM.\\nRather, we aim to explore the limit of LM as a general problem solver that explores its own thoughts\\nand guides its own exploration with deliberate reasoning as heuristics.\\nTask setup. We scrape data from GooBix, which contains 156 games of 5×5mini crosswords. As\\nwe observe adjacent games contain similar clues, we use 20 games with indices 1,6,···,91,96for\\ntesting, and games 136,141,146,151,156for prompting. For each task, the input describes the 5\\nhorizontal clues and 5 vertical clues, and the output should be a board of 5×5 = 25 letters to solve\\nthe crosswords. For evaluation, we consider three levels of success: the portion of correct letters (25\\nper game), words (10 per game), and games.\\nBaselines. We provide 5 example input-output pairs in the IO prompt, and in the CoT prompt\\nadditionally include intermediate words in the order h1..5 then v1..5. We run each prompt for 10\\nsamples and average the results.\\nToT setup. We leverage a depth-first search (Algorithm 2) that keeps exploring the most promising\\nsubsequent word clue until the state is no longer promising, then backtrack to the parent state to\\nexplore alternative thoughts. To make search tractable, subsequent thoughts are constrained not to\\nchange any filled words or letters, so that the ToT has at most 10 intermediate steps. For thought\\ngeneration, at each state we translate all existing thoughts (e.g. “h2.motor; h1.tasks” for the state\\nin Figure 6(a)) into letter constraints for remaining clues (e.g. “v1.To heap: tm ;...”) and prompt\\na proposal prompt 5times to come up with candidates for where and what to fill in the next word.\\nImportantly, we also prompt the LM to give a confidence level for different thoughts, and aggregate\\n7', metadata={'page': 6, 'source': 'tree_of_thought.pdf'}),\n",
       " Document(page_content='reasoning as planning with its internal world model, and proposes a MCTS-based method similar to\\nToT. However, its tasks are simpler than ours, and its framework lacks the modularity to incorporate\\ndifferent tree search algorithms.\\nSelf-reflection. Using LLMs to assess the viability of their own predictions is becoming an in-\\ncreasingly important procedure in problem solving. [ 28,20,24] introduced the “self-reflection”\\nmechanism, in which LMs provide feedback to their generation candidates. [ 4] improves LMs code\\ngeneration accuracy by injecting feedback messages generated by the LM itself based on its code\\nexecution results. Similarly, [ 17] also introduces “critic” or review steps over the actions and states,\\ndeciding the next action to take in solving computer operation tasks. Another recent work very\\nrelevant to ours is “self-eval guided decoding” [ 39]. Similar to our method, self-eval decoding\\nalso follows a tree-search procedure with leaves sampled from stochastic beam search decoding,\\nwhich are then evaluated by LLM itself with carefully prepared self-eval prompts. Their approach\\nhowever, uses the PAL formulation [ 8] which represents thoughts as codes, which makes it difficult\\nto tackle challenging tasks like creative writing which we consider in this paper. Our Tree-of-Thought\\nformulation is thus more versatile and handles challenging tasks on which GPT-4 only achieves very\\nlow accuracy with standard prompts.\\nProgram-guided LLM generation. Our proposal is also related to recent advancements that organize\\nLM’s behavior with systematic procedures [ 14,44,6,43] or symbolic program guidance. For example,\\nSchlag et al. [27] embeds LMs in an algorithmic search procedure to help solve problems like question\\nanswering step-by-step, in which the search trees are expanded by relevant paragraphs that might\\nprovide answers. This approach however differs from ours in that trees are expanded by sampling\\nexternal paragraphs instead of the LM’s own thoughts, and there is no reflection or voting steps.\\nAnother approach, LLM+P [ 18], goes one step further and delegates the actual planning process to a\\nclassical planner.\\nClassical search methods. Last but not least, our approach can be treated as a modern rendition\\nof classical search methods for problem solving. For example it can be considered as a heuristic\\nsearch algorithm like A* [ 10], in which the heuristic at each search node is provided by the LM’s self-\\nassessment. From this perspective, our method is also related to NeuroLogic A*esque decoding [ 19],\\nwhich is inspired by A* search but introduces look-ahead heuristics that are efficient for LMs to\\nimprove the beam-search or top-k sampling decoding. This method however is constrained to\\nsentence generation tasks, whereas our framework are designed for complex, multi-step problem\\nsolving guarded by value feedback.\\n6 Discussion\\nLimitations and future directions. Deliberate search such as ToT might not be necessary for many\\nexisting tasks that GPT-4 already excels at (see Appendix B.1), and as an initial step this work only\\nexplores three relatively simple tasks that challenges GPT-4 (see Appendix B.2 for some GPT-3.5\\nexperiment results) and calls of better search and planning abilities incorporated with LMs. However,\\nas we begin to deploy LMs for more real-world decision making applications (e.g. coding, data\\nanalysis, robotics, etc.), more complex tasks could emerge and present new opportunities to study\\nthese research questions. Also, search methods like ToT requires more resources (e.g. GPT-4 API\\ncost) than sampling methods in order to improve task performances, but the modular flexibility of\\nToT allows users to customize such performance-cost tradeoffs, and ongoing open-source efforts [ 32]\\nshould readily reduce such costs in the near future. More details about cost and efficiency are in\\nAppendix B.3. Lastly, this work focuses on using an off-the-shelf LM, and fine-tuning LMs using\\na ToT-style high-level counterfactual decision making (e.g. deliberating over potential choices for\\nthe next paragraph, instead of predicting the next token) might present opportunities to enhance the\\nproblem-solving capabilities of LMs.\\nConclusion. The associative “System 1” of LMs can be beneficially augmented by a “System 2”\\nbased on searching a tree of possible paths to the solution to a problem. The Tree of Thoughts\\nframework provides a way to translate classical insights about problem-solving into actionable\\nmethods for contemporary LMs. At the same time, LMs address a weakness of these classical\\nmethods, providing a way to solve complex problems that are not easily formalized, such as creative\\nwriting. We see this intersection of LMs with classical approaches to AI as an exciting direction.\\n9', metadata={'page': 8, 'source': 'tree_of_thought.pdf'}),\n",
       " Document(page_content='GĮŔũƜ\\njũƜŔũƜGĮŔũƜ\\njũƜŔũƜʱÊʲˤGjʱæʲˤ\\x1dĵÉGĮŔũƜ\\nˤjũƜŔũƜʱçʲˤ\\x1dĵÉˁ\\x92\\x1dʟʟʟʟaÊĠĵŗƓŤƆˤſĵŤòGĮŔũƜ\\nˤjũƜŔũƜʱíʲˤÉĵÉˤʱĵũŗŝʲʟʟʟʟʟʟˤˤʝˤƛĎĵũĈĎƜ)L[\\x03FRORU\\x03\\x0bE\\\\\\x03<XTLDQ\\x0c0DUN\\x03GLIIHUHQFH\\x03E\\\\\\x03FRORU\\nGĮŔũƜ\\njũƜŔũƜGĮŔũƜ\\njũƜŔũƜGĮŔũƜ\\nˤjũƜŔũƜʱçʲˤ\\x92òĦƙˤ\\x1dĵĮŝƓŝŤòĮçƆˤƀƓƜĎˤ\\x1dĵÉˤʱ\\x1dĵÉˁ\\x92\\x1dʲaÊĠĵŗƓŤƆˤſĵŤòGĮŔũƜ\\nˤjũƜŔũƜʱíʲˤÉŗòòˤĵƙˤ\\x9aĎĵũĈĎŤŝˤʱÉĵÉʲʟʟʟʟʟʟʟʟʟʟˤˤƛĎĵũĈĎƜ\\nʱçʲˤ\\x1dĎÊđĮˤĵƙˤ\\x9aĎĵũĈĎƜˤ\\x89ŗĵĭŔƜđĮĈˤʱ\\x1dĵÉʲʱÊʲˤGĮŔũƜˁjũƜŔũƜˤ\\x89ŗĵĭŔƜđĮĈˤʱGjʲFigure 1: Schematic illustrating various approaches to problem solving with LLMs. Each rectangle\\nbox represents a thought , which is a coherent language sequence that serves as an intermediate\\nstep toward problem solving. See concrete examples of how thoughts are generated, evaluated, and\\nsearched in Figures 2,4,6.\\nchoices instead of just picking one, and (2) evaluates its current status and actively looks ahead or\\nbacktracks to make more global decisions.\\nTo design such a planning process, we return to the origins of artificial intelligence (and cognitive\\nscience), drawing inspiration from the planning processes explored by Newell, Shaw, and Simon\\nstarting in the 1950s [ 21,22]. Newell and colleagues characterized problem solving [ 21] as search\\nthrough a combinatorial problem space, represented as a tree. We thus propose the Tree of Thoughts\\n(ToT) framework for general problem solving with language models. As Figure 1 illustrates, while\\nexisting methods (detailed below) sample continuous language sequences for problem solving, ToT\\nactively maintains a tree of thoughts, where each thought is a coherent language sequence that serves\\nas an intermediate step toward problem solving (Table 1). Such a high-level semantic unit allows the\\nLM to self-evaluate the progress different intermediate thoughts make towards solving the problem\\nthrough a deliberate reasoning process that is also instantiated in language (Figures 2,4,6). This\\nimplementation of search heuristics via LM self-evaluation and deliberation is novel, as previous\\nsearch heuristics are either programmed or learned. Finally, we combine this language-based\\ncapability to generate and evaluate diverse thoughts with search algorithms, such as breadth-first\\nsearch (BFS) or depth-first search (DFS), which allow systematic exploration of the tree of thoughts\\nwith lookahead and backtracking.\\nEmpirically, we propose three new problems that challenge existing LM inference methods even with\\nthe state-of-the-art language model, GPT-4 [ 23]: Game of 24, Creative Writing, and Crosswords\\n(Table 1). These tasks require deductive, mathematical, commonsense, lexical reasoning abilities,\\nand a way to incorporate systematic planning or search. We show ToT obtains superior results on\\nall three tasks by being general and flexible enough to support different levels of thoughts, different\\nways to generate and evaluate thoughts, and different search algorithms that adapt to the nature of\\ndifferent problems. We also analyze how such choices affect model performances via systematic\\nablations and discuss future directions to better train and use LMs.\\n2 Background\\nWe first formalize some existing methods that use large language models for problem-solving,\\nwhich our approach is inspired by and later compared with. We use pθto denote a pre-trained LM\\nwith parameters θ, and lowercase letters x, y, z, s, ···to denote a language sequence , i.e.x=\\n(x[1],···, x[n])where each x[i]is a token, so that pθ(x) =Qn\\ni=1pθ(x[i]|x[1...i]). We use uppercase\\nletters S,···to denote a collection of language sequences.\\nInput-output (IO) prompting is the most common way to turn a problem input xinto output\\nywith LM: y∼pθ(y|promptIO(x)), where promptIO(x)wraps input xwith task instructions\\nand/or few-shot input-output examples. For simplicity, let us denote pprompt\\nθ(output |input ) =\\npθ(output |prompt (input )), so that IO prompting can be formulated as y∼pIO\\nθ(y|x).\\n2', metadata={'page': 1, 'source': 'tree_of_thought.pdf'}),\n",
       " Document(page_content='Chain-of-thought (CoT) prompting [38] was proposed to address cases where the mapping of\\ninput xto output yis non-trivial (e.g. when xis a math question and yis the final numerical answer).\\nThe key idea is to introduce a chain of thoughts z1,···, znto bridge xandy, where each ziis a\\ncoherent language sequence that serves as a meaningful intermediate step toward problem solving\\n(e.g.zicould be an intermediate equation for math QA). To solve problems with CoT, each thought\\nzi∼pCoT\\nθ(zi|x, z1···i−1)is sampled sequentially, then the output y∼pCoT\\nθ(y|x, z1···n). In\\npractice, [z1···n, y]∼pCoT\\nθ(z1···n, y|x)is sampled as a continuous language sequence, and the\\ndecomposition of thoughts (e.g. is each zia phrase, a sentence, or a paragraph) is left ambiguous.\\nSelf-consistency with CoT (CoT-SC) [36] is an ensemble approach that samples ki.i.d. chains\\nof thought: [z(i)\\n1···n, y(i)]∼pCoT\\nθ(z1···n, y|x) (i= 1···k), then returns the most frequent output:\\narg max y#{i|y(i)=y}. CoT-SC improves upon CoT, because there are generally different\\nthought processes for the same problem (e.g. different ways to prove the same theorem), and the\\noutput decision can be more faithful by exploring a richer set of thoughts. However, within each\\nchain there is no local exploration of different thought steps, and the “most frequent” heuristic only\\napplies when the output space is limited (e.g. multi-choice QA).\\n3 Tree of Thoughts: Deliberate Problem Solving with LM\\nA genuine problem-solving process involves the repeated use of available informa-\\ntion to initiate exploration, which discloses, in turn, more information until a way\\nto attain the solution is finally discovered.—— Newell et al. [21]\\nResearch on human problem-solving suggests that people search through a combinatorial problem-\\nspace – a tree where the nodes represent partial solutions, and the branches correspond to operators\\nthat modify them [ 21,22]. Which branch to take is determined by heuristics that help to navigate the\\nproblem-space and guide the problem-solver towards a solution. This perspective highlights two key\\nshortcomings of existing approaches that use LMs to solve general problems: 1) Locally, they do not\\nexplore different continuations within a thought process – the branches of the tree. 2) Globally, they\\ndo not incorporate any type of planning, lookahead, or backtracking to help evaluate these different\\noptions – the kind of heuristic-guided search that seems characteristic of human problem-solving.\\nTo address these shortcomings, we introduce Tree of Thoughts (ToT) , a paradigm that allows LMs to\\nexplore multiple reasoning paths over thoughts (Figure 1(c)). ToT frames any problem as a search\\nover a tree, where each node is a state s= [x, z1···i]representing a partial solution with the input and\\nthe sequence of thoughts so far. A specific instantiation of ToT involves answering four questions:\\n1. How to decompose the intermediate process into thought steps; 2. How to generate potential\\nthoughts from each state; 3. How to heuristically evaluate states; 4. What search algorithm to use.\\n1. Thought decomposition. While CoT samples thoughts coherently without explicit decomposition,\\nToT leverages problem properties to design and decompose intermediate thought steps. As Table 1\\nshows, depending on different problems, a thought could be a couple of words (Crosswords), a line of\\nequation (Game of 24), or a whole paragraph of writing plan (Creative Writing). In general, a thought\\nshould be “small” enough so that LMs can generate promising and diverse samples (e.g. generating\\na whole book is usually too “big” to be coherent), yet “big” enough so that LMs can evaluate its\\nprospect toward problem solving (e.g. generating one token is usually too “small” to evaluate).\\n2. Thought generator G(pθ, s, k).Given a tree state s= [x, z1···i], we consider two strategies to\\ngenerate kcandidates for the next thought step:\\n(a)Sample i.i.d. thoughts from a CoT prompt (Creative Writing, Figure 4): z(j)∼\\npCoT\\nθ(zi+1|s) =pCoT\\nθ(zi+1|x, z1···i) (j= 1···k). This works better when the thought\\nspace is rich (e.g. each thought is a paragraph), and i.i.d. samples lead to diversity;\\n(b)Propose thoughts sequentially using a “propose prompt” (Game of 24, Figure 2; Crosswords,\\nFigure 6): [z(1),···, z(k)]∼ppropose\\nθ(z(1···k)\\ni+1|s). This works better when the thought\\nspace is more constrained (e.g. each thought is just a word or a line), so proposing different\\nthoughts in the same context avoids duplication.\\n3. State evaluator V(pθ, S).Given a frontier of different states, the state evaluator evaluates the\\nprogress they make towards solving the problem, serving as a heuristic for the search algorithm\\nto determine which states to keep exploring and in which order. While heuristics are a standard\\napproach to solving search problems, they are typically either programmed (e.g. DeepBlue [ 3]) or\\n3', metadata={'page': 2, 'source': 'tree_of_thought.pdf'})]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector Database\n",
    "query = \"How do the authors make search tractable\"\n",
    "db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISS Vector Embeddings and Vesctor Store\n",
    "\n",
    "from langchain_community.vectorstores import FAISS \n",
    "db_1 = FAISS.from_documents(pdf_documents[:30], embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='µŗƓŤòˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòˤĵƙˤʁˤŝĎĵŗƜˤŔÊŗÊĈŗÊŔĎŝʛˤ\\x9aĎòˤòĮíˤŝòĮŤòĮçòˤĵƙˤòÊçĎˤŔÊŗÊĈŗÊŔĎˤĭũŝƜˤæòʝˤɾʛˤGƜˤƓŝĮ˙ƛˤíđƙƙƓçũĦƜˤƘĵˤíĵˤÊˤĎÊĮíŝŤÊĮíˤđƙˤƆĵũˤĠũŝƜˤŝŤÊĮíˤĵĮˤƆĵũŗˤĎÊĮíŝʛˤɿʛˤGƜˤçÊũĈĎƜˤĎđĭˤĵƙƙˤĈũÊŗíˤƛĎÊƜˤŝŔÊçòˤŝĭòĦĦòíˤĵƙˤŝòÊŗòíˤŝŤòÊģʛˤʀʛˤµĎòĮˤŝĎòˤíƓíĮ˒ƛˤĦđģòˤÊˤĈũƆˤƀĎĵˤƀÊŝˤƛŗƆđĮĈˤƘĵˤŔƓçģˤĎòŗˤũŔʜˤŝĎòˤŝŤÊŗŤòíˤũŝđĮĈˤŝƓĈĮˤĦÊĮĈũÊĈòʛˤʁʛˤ)ÊçĎˤŔòŗŝĵĮˤƀĎĵˤģĮĵƀŝˤƆĵũˤĎÊŝˤÊˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮˤĵƙˤƀĎĵˤƆĵũˤÊŗòʛˤˤɾʛˤGĮƜŗĵíũçòˤÊĮíˤòƅŔĦÊđĮˤƛĎòˤƘòçĎĮƓŖũòˤĵƙˤíĵđĮĈˤÊˤĎÊĮíŝŤÊĮíˤɿʛˤ\\x92ƀƓŤçĎˤƘĵˤÊˤŝŤĵŗƆˤÊæĵũƜˤÊĮˤÊŝƜŗĵĮÊũƜ˙ŝˤƚđŗŝƜˤƛđĭòˤđĮˤŝŔÊçòˤʀʛˤ#òŝçŗđæòˤÊˤŝƓƜũÊƜƓĵĮˤƀĎòŗòˤÊˤƀĵĭÊĮˤũŝòŝˤŝƓĈĮˤĦÊĮĈũÊĈòˤƘĵˤÊſĵƓíˤũĮƀÊĮŤòíˤÊƜŤòĮƜƓĵĮˤʁʛˤ\\x9aĎòˤƚđĮÊĦˤŔÊŗÊĈŗÊŔĎˤòƅŔĦÊđĮŝˤĎĵƀˤòſòŗƆĵĮòˤĎÊŝˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮŝˤĵƙˤĵƜĎòŗŝɾʛˤGĮƜŗĵíũçƜƓĵĮˤƘĵˤÊĮˤũĮũŝũÊĦˤŝòĦƙˊĎòĦŔˤæĵĵģʜˤĭòĮƜƓĵĮđĮĈˤÊˤĎÊĮíŝŤÊĮíˤÊŝˤÊˤĭòŤÊŔĎĵŗˤƗĵŗˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʛˤɿʛˤ#ƓŝçũŝŝˤƛĎòˤũĮòƅŔòçŤòíˤƛĎđĮĈŝˤĦòÊŗĮòíˤƚŗĵĭˤÊŝƜŗĵĮÊũŤŝʜˤđĮçĦũíđĮĈˤƛĎòˤŝĭòĦĦˤĵƙˤŝŔÊçòʛˤʀʛˤ#òŝçŗđæòˤÊˤƀĵĭÊĮ˙ŝˤçĦòſòŗˤƘÊçƜƓçˤƗĵŗˤÊſĵƓíđĮĈˤũĮƀÊĮŤòíˤÊƜŤòĮƜƓĵĮˤÊƜˤÊˤæÊŗʛˤʁʛˤ\\x1dĵĮŤòĭŔĦÊŤòˤĎĵƀˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮŝˤĵƙˤĵĮòŝòĦƙˤçÊĮˤŝĎÊŔòˤĵĮò˙ŝˤƓíòĮƜƓŤƆʛʱÊʲˤGĮŔũƜʱæʲˤ\\x89ĦÊĮŝʱʀˤĭĵŗòˤĵĭƓƜŤòíʲʱçʲˤ´ĵŤòŝ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝʟˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛʱɽʫʂˤſĵŤòŝʲ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝʟˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝʟˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝʟˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛʱʀʫʂˤſĵŤòŝʲʟɾɿGĮŔũƜ\\x89ĦÊĮˤɾ\\x89ĦÊĮˤɿʟʟ\\x89ÊŝŝÊĈòɾ\\x89ÊŝŝÊĈòɿʟʟ)L[\\x03FRORU\\x03\\x0bE\\\\\\x03<XTLDQ\\x0cµŗƓŤòˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòˤĵƙˤʁˤŝĎĵŗƜˤŔÊŗÊĈŗÊŔĎŝʛˤ\\x9aĎòˤòĮíˤŝòĮŤòĮçòˤĵƙˤòÊçĎˤŔÊŗÊĈŗÊŔĎˤĭũŝƜˤæòʝˤɾʛˤGƜˤƓŝĮ˙ƛˤíđƙƙƓçũĦƜˤƘĵˤíĵˤÊˤĎÊĮíŝŤÊĮíˤđƙˤƆĵũˤĠũŝƜˤŝŤÊĮíˤĵĮˤƆĵũŗˤĎÊĮíŝʛˤɿʛˤGƜˤçÊũĈĎƜˤĎđĭˤĵƙƙˤĈũÊŗíˤƛĎÊƜˤŝŔÊçòˤŝĭòĦĦòíˤĵƙˤŝòÊŗòíˤŝŤòÊģʛˤʀʛˤµĎòĮˤŝĎòˤíƓíĮ˒ƛˤĦđģòˤÊˤĈũƆˤƀĎĵˤƀÊŝˤƛŗƆđĮĈˤƘĵˤŔƓçģˤĎòŗˤũŔʜˤŝĎòˤŝŤÊŗŤòíˤũŝđĮĈˤŝƓĈĮˤĦÊĮĈũÊĈòʛˤʁʛˤ)ÊçĎˤŔòŗŝĵĮˤƀĎĵˤģĮĵƀŝˤƆĵũˤĎÊŝˤÊˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮˤĵƙˤƀĎĵˤƆĵũˤÊŗòʛˤˤɾʛˤGĮƜŗĵíũçòˤÊĮíˤòƅŔĦÊđĮˤƛĎòˤƘòçĎĮƓŖũòˤĵƙˤíĵđĮĈˤÊˤĎÊĮíŝŤÊĮíˤɿʛˤ\\x92ƀƓŤçĎˤƘĵˤÊˤŝŤĵŗƆˤÊæĵũƜˤÊĮˤÊŝƜŗĵĮÊũƜ˙ŝˤƚđŗŝƜˤƛđĭòˤđĮˤŝŔÊçòˤʀʛˤ#òŝçŗđæòˤÊˤŝƓƜũÊƜƓĵĮˤƀĎòŗòˤÊˤƀĵĭÊĮˤũŝòŝˤŝƓĈĮˤĦÊĮĈũÊĈòˤƘĵˤÊſĵƓíˤũĮƀÊĮŤòíˤÊƜŤòĮƜƓĵĮˤʁʛˤ\\x9aĎòˤƚđĮÊĦˤŔÊŗÊĈŗÊŔĎˤòƅŔĦÊđĮŝˤĎĵƀˤòſòŗƆĵĮòˤĎÊŝˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮŝˤĵƙˤĵƜĎòŗŝɾʛˤGĮƜŗĵíũçƜƓĵĮˤƘĵˤÊĮˤũĮũŝũÊĦˤŝòĦƙˊĎòĦŔˤæĵĵģʜˤĭòĮƜƓĵĮđĮĈˤÊˤĎÊĮíŝŤÊĮíˤÊŝˤÊˤĭòŤÊŔĎĵŗˤƗĵŗˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʛˤɿʛˤ#ƓŝçũŝŝˤƛĎòˤũĮòƅŔòçŤòíˤƛĎđĮĈŝˤĦòÊŗĮòíˤƚŗĵĭˤÊŝƜŗĵĮÊũŤŝʜˤđĮçĦũíđĮĈˤƛĎòˤŝĭòĦĦˤĵƙˤŝŔÊçòʛˤʀʛˤ#òŝçŗđæòˤÊˤƀĵĭÊĮ˙ŝˤçĦòſòŗˤƘÊçƜƓçˤƗĵŗˤÊſĵƓíđĮĈˤũĮƀÊĮŤòíˤÊƜŤòĮƜƓĵĮˤÊƜˤÊˤæÊŗʛˤʁʛˤ\\x1dĵĮŤòĭŔĦÊŤòˤĎĵƀˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮŝˤĵƙˤĵĮòŝòĦƙˤçÊĮˤŝĎÊŔòˤĵĮò˙ŝˤƓíòĮƜƓŤƆʛʱÊʲˤGĮŔũƜʱæʲˤ\\x89ĦÊĮŝʱçʲˤ´ĵŤòŝ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛGĮŔũƜ\\x89ĦÊĮˤɾˤ\\x89ĦÊĮˤɿˤˤʟʟ\\x89ÊŝŝÊĈòɾ\\x89ÊŝŝÊĈòɿʟʟɽʫʂˤſĵŤòŝ\\x89ĦÊĮˤɾˤˤˤʟʛʟʛɾʟʛɿʟʟʀʫʂˤſĵŤòŝ\\x89ĦÊĮˤʀˁʂˤˤˤ8VH\\x03UHG\\x12JUHHQ\\x03WR\\x03VKRZ\\x03ILQDO\\x03FKRLFH\\nĮʫʂˤſĵŤòŝ\\x89ĦÊĮˤɿˤˤˤ\\n\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛFigure 4: A step of deliberate search in a randomly picked Creative Writing task. Given the input, the\\nLM samples 5 different plans, then votes 5 times to decide which plan is best. The majority choice is\\nused to consequently write the output passage with the same sample-vote procedure.\\nIO CoT ToT IO\\n+refineToT\\n+refine468\\n(a) GPT-4 coherency scores\\nCoT > ToT Similar ToT > CoT010203040\\n213841(b) Human coherency comparison\\nFigure 5: Creative Writing results.Method Success Rate (%)\\nLetter Word Game\\nIO 38.7 14 0\\nCoT 40.6 15.6 1\\nToT (ours) 78 60 20\\n+best state 82.4 67.5 35\\n-prune 65.4 41.5 5\\n-backtrack 54.6 20 5\\nTable 3: Mini Crosswords results.\\nit improves IO coherency score from 6.19 to 7.67, and ToT coherency score from 7.56 to 7.91. We\\nbelieve it could be thought of as a third approach to thought generation in the ToT framework, where\\nnew thoughts can arise from refining old thoughts instead of i.i.d. or sequentially generated.\\n4.3 Mini crosswords\\nIn Game of 24 and Creative Writing, ToT is relatively shallow — at most 3 thought steps are needed\\nto reach the final output. Here we explore 5×5mini crosswords as a harder search problem involving\\nnatural language. Again, the goal is not just to solve the task, as more general crosswords can be\\nreadily solved with specialized NLP pipelines [ 34] that leverages large-scale retrieval instead of LM.\\nRather, we aim to explore the limit of LM as a general problem solver that explores its own thoughts\\nand guides its own exploration with deliberate reasoning as heuristics.\\nTask setup. We scrape data from GooBix, which contains 156 games of 5×5mini crosswords. As\\nwe observe adjacent games contain similar clues, we use 20 games with indices 1,6,···,91,96for\\ntesting, and games 136,141,146,151,156for prompting. For each task, the input describes the 5\\nhorizontal clues and 5 vertical clues, and the output should be a board of 5×5 = 25 letters to solve\\nthe crosswords. For evaluation, we consider three levels of success: the portion of correct letters (25\\nper game), words (10 per game), and games.\\nBaselines. We provide 5 example input-output pairs in the IO prompt, and in the CoT prompt\\nadditionally include intermediate words in the order h1..5 then v1..5. We run each prompt for 10\\nsamples and average the results.\\nToT setup. We leverage a depth-first search (Algorithm 2) that keeps exploring the most promising\\nsubsequent word clue until the state is no longer promising, then backtrack to the parent state to\\nexplore alternative thoughts. To make search tractable, subsequent thoughts are constrained not to\\nchange any filled words or letters, so that the ToT has at most 10 intermediate steps. For thought\\ngeneration, at each state we translate all existing thoughts (e.g. “h2.motor; h1.tasks” for the state\\nin Figure 6(a)) into letter constraints for remaining clues (e.g. “v1.To heap: tm ;...”) and prompt\\na proposal prompt 5times to come up with candidates for where and what to fill in the next word.\\nImportantly, we also prompt the LM to give a confidence level for different thoughts, and aggregate\\n7', metadata={'source': 'tree_of_thought.pdf', 'page': 6}),\n",
       " Document(page_content='reasoning as planning with its internal world model, and proposes a MCTS-based method similar to\\nToT. However, its tasks are simpler than ours, and its framework lacks the modularity to incorporate\\ndifferent tree search algorithms.\\nSelf-reflection. Using LLMs to assess the viability of their own predictions is becoming an in-\\ncreasingly important procedure in problem solving. [ 28,20,24] introduced the “self-reflection”\\nmechanism, in which LMs provide feedback to their generation candidates. [ 4] improves LMs code\\ngeneration accuracy by injecting feedback messages generated by the LM itself based on its code\\nexecution results. Similarly, [ 17] also introduces “critic” or review steps over the actions and states,\\ndeciding the next action to take in solving computer operation tasks. Another recent work very\\nrelevant to ours is “self-eval guided decoding” [ 39]. Similar to our method, self-eval decoding\\nalso follows a tree-search procedure with leaves sampled from stochastic beam search decoding,\\nwhich are then evaluated by LLM itself with carefully prepared self-eval prompts. Their approach\\nhowever, uses the PAL formulation [ 8] which represents thoughts as codes, which makes it difficult\\nto tackle challenging tasks like creative writing which we consider in this paper. Our Tree-of-Thought\\nformulation is thus more versatile and handles challenging tasks on which GPT-4 only achieves very\\nlow accuracy with standard prompts.\\nProgram-guided LLM generation. Our proposal is also related to recent advancements that organize\\nLM’s behavior with systematic procedures [ 14,44,6,43] or symbolic program guidance. For example,\\nSchlag et al. [27] embeds LMs in an algorithmic search procedure to help solve problems like question\\nanswering step-by-step, in which the search trees are expanded by relevant paragraphs that might\\nprovide answers. This approach however differs from ours in that trees are expanded by sampling\\nexternal paragraphs instead of the LM’s own thoughts, and there is no reflection or voting steps.\\nAnother approach, LLM+P [ 18], goes one step further and delegates the actual planning process to a\\nclassical planner.\\nClassical search methods. Last but not least, our approach can be treated as a modern rendition\\nof classical search methods for problem solving. For example it can be considered as a heuristic\\nsearch algorithm like A* [ 10], in which the heuristic at each search node is provided by the LM’s self-\\nassessment. From this perspective, our method is also related to NeuroLogic A*esque decoding [ 19],\\nwhich is inspired by A* search but introduces look-ahead heuristics that are efficient for LMs to\\nimprove the beam-search or top-k sampling decoding. This method however is constrained to\\nsentence generation tasks, whereas our framework are designed for complex, multi-step problem\\nsolving guarded by value feedback.\\n6 Discussion\\nLimitations and future directions. Deliberate search such as ToT might not be necessary for many\\nexisting tasks that GPT-4 already excels at (see Appendix B.1), and as an initial step this work only\\nexplores three relatively simple tasks that challenges GPT-4 (see Appendix B.2 for some GPT-3.5\\nexperiment results) and calls of better search and planning abilities incorporated with LMs. However,\\nas we begin to deploy LMs for more real-world decision making applications (e.g. coding, data\\nanalysis, robotics, etc.), more complex tasks could emerge and present new opportunities to study\\nthese research questions. Also, search methods like ToT requires more resources (e.g. GPT-4 API\\ncost) than sampling methods in order to improve task performances, but the modular flexibility of\\nToT allows users to customize such performance-cost tradeoffs, and ongoing open-source efforts [ 32]\\nshould readily reduce such costs in the near future. More details about cost and efficiency are in\\nAppendix B.3. Lastly, this work focuses on using an off-the-shelf LM, and fine-tuning LMs using\\na ToT-style high-level counterfactual decision making (e.g. deliberating over potential choices for\\nthe next paragraph, instead of predicting the next token) might present opportunities to enhance the\\nproblem-solving capabilities of LMs.\\nConclusion. The associative “System 1” of LMs can be beneficially augmented by a “System 2”\\nbased on searching a tree of possible paths to the solution to a problem. The Tree of Thoughts\\nframework provides a way to translate classical insights about problem-solving into actionable\\nmethods for contemporary LMs. At the same time, LMs address a weakness of these classical\\nmethods, providing a way to solve complex problems that are not easily formalized, such as creative\\nwriting. We see this intersection of LMs with classical approaches to AI as an exciting direction.\\n9', metadata={'source': 'tree_of_thought.pdf', 'page': 8}),\n",
       " Document(page_content='GĮŔũƜ\\njũƜŔũƜGĮŔũƜ\\njũƜŔũƜʱÊʲˤGjʱæʲˤ\\x1dĵÉGĮŔũƜ\\nˤjũƜŔũƜʱçʲˤ\\x1dĵÉˁ\\x92\\x1dʟʟʟʟaÊĠĵŗƓŤƆˤſĵŤòGĮŔũƜ\\nˤjũƜŔũƜʱíʲˤÉĵÉˤʱĵũŗŝʲʟʟʟʟʟʟˤˤʝˤƛĎĵũĈĎƜ)L[\\x03FRORU\\x03\\x0bE\\\\\\x03<XTLDQ\\x0c0DUN\\x03GLIIHUHQFH\\x03E\\\\\\x03FRORU\\nGĮŔũƜ\\njũƜŔũƜGĮŔũƜ\\njũƜŔũƜGĮŔũƜ\\nˤjũƜŔũƜʱçʲˤ\\x92òĦƙˤ\\x1dĵĮŝƓŝŤòĮçƆˤƀƓƜĎˤ\\x1dĵÉˤʱ\\x1dĵÉˁ\\x92\\x1dʲaÊĠĵŗƓŤƆˤſĵŤòGĮŔũƜ\\nˤjũƜŔũƜʱíʲˤÉŗòòˤĵƙˤ\\x9aĎĵũĈĎŤŝˤʱÉĵÉʲʟʟʟʟʟʟʟʟʟʟˤˤƛĎĵũĈĎƜ\\nʱçʲˤ\\x1dĎÊđĮˤĵƙˤ\\x9aĎĵũĈĎƜˤ\\x89ŗĵĭŔƜđĮĈˤʱ\\x1dĵÉʲʱÊʲˤGĮŔũƜˁjũƜŔũƜˤ\\x89ŗĵĭŔƜđĮĈˤʱGjʲFigure 1: Schematic illustrating various approaches to problem solving with LLMs. Each rectangle\\nbox represents a thought , which is a coherent language sequence that serves as an intermediate\\nstep toward problem solving. See concrete examples of how thoughts are generated, evaluated, and\\nsearched in Figures 2,4,6.\\nchoices instead of just picking one, and (2) evaluates its current status and actively looks ahead or\\nbacktracks to make more global decisions.\\nTo design such a planning process, we return to the origins of artificial intelligence (and cognitive\\nscience), drawing inspiration from the planning processes explored by Newell, Shaw, and Simon\\nstarting in the 1950s [ 21,22]. Newell and colleagues characterized problem solving [ 21] as search\\nthrough a combinatorial problem space, represented as a tree. We thus propose the Tree of Thoughts\\n(ToT) framework for general problem solving with language models. As Figure 1 illustrates, while\\nexisting methods (detailed below) sample continuous language sequences for problem solving, ToT\\nactively maintains a tree of thoughts, where each thought is a coherent language sequence that serves\\nas an intermediate step toward problem solving (Table 1). Such a high-level semantic unit allows the\\nLM to self-evaluate the progress different intermediate thoughts make towards solving the problem\\nthrough a deliberate reasoning process that is also instantiated in language (Figures 2,4,6). This\\nimplementation of search heuristics via LM self-evaluation and deliberation is novel, as previous\\nsearch heuristics are either programmed or learned. Finally, we combine this language-based\\ncapability to generate and evaluate diverse thoughts with search algorithms, such as breadth-first\\nsearch (BFS) or depth-first search (DFS), which allow systematic exploration of the tree of thoughts\\nwith lookahead and backtracking.\\nEmpirically, we propose three new problems that challenge existing LM inference methods even with\\nthe state-of-the-art language model, GPT-4 [ 23]: Game of 24, Creative Writing, and Crosswords\\n(Table 1). These tasks require deductive, mathematical, commonsense, lexical reasoning abilities,\\nand a way to incorporate systematic planning or search. We show ToT obtains superior results on\\nall three tasks by being general and flexible enough to support different levels of thoughts, different\\nways to generate and evaluate thoughts, and different search algorithms that adapt to the nature of\\ndifferent problems. We also analyze how such choices affect model performances via systematic\\nablations and discuss future directions to better train and use LMs.\\n2 Background\\nWe first formalize some existing methods that use large language models for problem-solving,\\nwhich our approach is inspired by and later compared with. We use pθto denote a pre-trained LM\\nwith parameters θ, and lowercase letters x, y, z, s, ···to denote a language sequence , i.e.x=\\n(x[1],···, x[n])where each x[i]is a token, so that pθ(x) =Qn\\ni=1pθ(x[i]|x[1...i]). We use uppercase\\nletters S,···to denote a collection of language sequences.\\nInput-output (IO) prompting is the most common way to turn a problem input xinto output\\nywith LM: y∼pθ(y|promptIO(x)), where promptIO(x)wraps input xwith task instructions\\nand/or few-shot input-output examples. For simplicity, let us denote pprompt\\nθ(output |input ) =\\npθ(output |prompt (input )), so that IO prompting can be formulated as y∼pIO\\nθ(y|x).\\n2', metadata={'source': 'tree_of_thought.pdf', 'page': 1}),\n",
       " Document(page_content='Chain-of-thought (CoT) prompting [38] was proposed to address cases where the mapping of\\ninput xto output yis non-trivial (e.g. when xis a math question and yis the final numerical answer).\\nThe key idea is to introduce a chain of thoughts z1,···, znto bridge xandy, where each ziis a\\ncoherent language sequence that serves as a meaningful intermediate step toward problem solving\\n(e.g.zicould be an intermediate equation for math QA). To solve problems with CoT, each thought\\nzi∼pCoT\\nθ(zi|x, z1···i−1)is sampled sequentially, then the output y∼pCoT\\nθ(y|x, z1···n). In\\npractice, [z1···n, y]∼pCoT\\nθ(z1···n, y|x)is sampled as a continuous language sequence, and the\\ndecomposition of thoughts (e.g. is each zia phrase, a sentence, or a paragraph) is left ambiguous.\\nSelf-consistency with CoT (CoT-SC) [36] is an ensemble approach that samples ki.i.d. chains\\nof thought: [z(i)\\n1···n, y(i)]∼pCoT\\nθ(z1···n, y|x) (i= 1···k), then returns the most frequent output:\\narg max y#{i|y(i)=y}. CoT-SC improves upon CoT, because there are generally different\\nthought processes for the same problem (e.g. different ways to prove the same theorem), and the\\noutput decision can be more faithful by exploring a richer set of thoughts. However, within each\\nchain there is no local exploration of different thought steps, and the “most frequent” heuristic only\\napplies when the output space is limited (e.g. multi-choice QA).\\n3 Tree of Thoughts: Deliberate Problem Solving with LM\\nA genuine problem-solving process involves the repeated use of available informa-\\ntion to initiate exploration, which discloses, in turn, more information until a way\\nto attain the solution is finally discovered.—— Newell et al. [21]\\nResearch on human problem-solving suggests that people search through a combinatorial problem-\\nspace – a tree where the nodes represent partial solutions, and the branches correspond to operators\\nthat modify them [ 21,22]. Which branch to take is determined by heuristics that help to navigate the\\nproblem-space and guide the problem-solver towards a solution. This perspective highlights two key\\nshortcomings of existing approaches that use LMs to solve general problems: 1) Locally, they do not\\nexplore different continuations within a thought process – the branches of the tree. 2) Globally, they\\ndo not incorporate any type of planning, lookahead, or backtracking to help evaluate these different\\noptions – the kind of heuristic-guided search that seems characteristic of human problem-solving.\\nTo address these shortcomings, we introduce Tree of Thoughts (ToT) , a paradigm that allows LMs to\\nexplore multiple reasoning paths over thoughts (Figure 1(c)). ToT frames any problem as a search\\nover a tree, where each node is a state s= [x, z1···i]representing a partial solution with the input and\\nthe sequence of thoughts so far. A specific instantiation of ToT involves answering four questions:\\n1. How to decompose the intermediate process into thought steps; 2. How to generate potential\\nthoughts from each state; 3. How to heuristically evaluate states; 4. What search algorithm to use.\\n1. Thought decomposition. While CoT samples thoughts coherently without explicit decomposition,\\nToT leverages problem properties to design and decompose intermediate thought steps. As Table 1\\nshows, depending on different problems, a thought could be a couple of words (Crosswords), a line of\\nequation (Game of 24), or a whole paragraph of writing plan (Creative Writing). In general, a thought\\nshould be “small” enough so that LMs can generate promising and diverse samples (e.g. generating\\na whole book is usually too “big” to be coherent), yet “big” enough so that LMs can evaluate its\\nprospect toward problem solving (e.g. generating one token is usually too “small” to evaluate).\\n2. Thought generator G(pθ, s, k).Given a tree state s= [x, z1···i], we consider two strategies to\\ngenerate kcandidates for the next thought step:\\n(a)Sample i.i.d. thoughts from a CoT prompt (Creative Writing, Figure 4): z(j)∼\\npCoT\\nθ(zi+1|s) =pCoT\\nθ(zi+1|x, z1···i) (j= 1···k). This works better when the thought\\nspace is rich (e.g. each thought is a paragraph), and i.i.d. samples lead to diversity;\\n(b)Propose thoughts sequentially using a “propose prompt” (Game of 24, Figure 2; Crosswords,\\nFigure 6): [z(1),···, z(k)]∼ppropose\\nθ(z(1···k)\\ni+1|s). This works better when the thought\\nspace is more constrained (e.g. each thought is just a word or a line), so proposing different\\nthoughts in the same context avoids duplication.\\n3. State evaluator V(pθ, S).Given a frontier of different states, the state evaluator evaluates the\\nprogress they make towards solving the problem, serving as a heuristic for the search algorithm\\nto determine which states to keep exploring and in which order. While heuristics are a standard\\napproach to solving search problems, they are typically either programmed (e.g. DeepBlue [ 3]) or\\n3', metadata={'source': 'tree_of_thought.pdf', 'page': 2})]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FAISS Vector Database\n",
    "query = \"How do the authors make search tractable\"\n",
    "db_1.similarity_search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now onto Video 5-LangChain Series-Advanced RAG Q&A Chatbot with Chain ANd Retrievers Using Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ollama(model='llama2:latest')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "# Load Ollama Llama2 model\n",
    "llm = Ollama(model=\"llama2:latest\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desing ChatPrompt Template\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the following question based only on the provided context.\n",
    "Think step by step before providing a detailed answer.\n",
    "I will tip you $1000 if the user finds the answer helpful.\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "Question: {input}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain introduction\n",
    "# Create Stuff Document Chain\n",
    "\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'AzureOpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001CE73B599D0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Retrievers: A retriever is an interface that returns documents given an unstructured query. It is more general than a vector store. \n",
    "A retriever does not need to be able to store documents, only to return (or retrieve) them. Vector stores can ve used as the backbone\n",
    "of a retriever, but there are other types of retrievers as well.\n",
    "\"\"\"\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Retrieval chain: This chain takes in a user inquiry, which is then passed to the retriever to fetch relevant documents. \n",
    "Those documents (and original inputs) are then passed to an LLM to generate a response.\n",
    "\"\"\"\n",
    "\n",
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"Chain of thought is lacking in some areas.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Answer: Yes, the chain of thought can be limited in certain areas. Here are some potential limitations and ways to address them:\\n\\n1. Limited contextual understanding: LMs may struggle to understand the context of a problem or task, leading to suboptimal solutions. To address this, researchers can incorporate external knowledge sources, such as databases or knowledge graphs, to improve the LM's understanding of the context.\\n2. Lack of common sense: LMs may not have the same level of common sense or real-world experience as humans, which can lead to unexpected or illogical solutions. To address this, researchers can incorporate more diverse and extensive training data to improve the LM's ability to understand the nuances of human reasoning.\\n3. Limited creativity: LMs may struggle to come up with novel or innovative solutions due to their reliance on statistical patterns in the training data. To address this, researchers can incorporate more diverse and unexpected training data to improve the LM's ability to think outside the box.\\n4. Difficulty with ambiguity: LMs may struggle with ambiguous or vague problems, leading to suboptimal solutions. To address this, researchers can incorporate more contextual information or use external knowledge sources to help disambiguate the problem.\\n5. Limited ability to reason about abstract concepts: LMs may struggle to reason about abstract concepts or ideas that are not well-represented in the training data. To address this, researchers can incorporate more diverse and extensive training data to improve the LM's ability to reason about abstract concepts.\\n6. Limited ability to handle multi-step problems: LMs may struggle with multi-step problems or tasks that require multiple stages of processing. To address this, researchers can incorporate more sophisticated reasoning mechanisms or use external knowledge sources to help break down complex problems into smaller, more manageable components.\\n7. Limited ability to handle incomplete information: LMs may struggle with problems that involve incomplete information or uncertainty. To address this, researchers can incorporate more robust inference mechanisms or use external knowledge sources to help reason about uncertain or incomplete information.\\n8. Limited ability to handle dynamic environments: LMs may struggle with problems that involve rapidly changing contexts or environments. To address this, researchers can incorporate more adaptive and responsive reasoning mechanisms or use external knowledge sources to help the LM keep up with changing conditions.\\n9. Limited ability to handle human-AI collaboration: LMs may struggle with problems that require collaboration between humans and AI systems. To address this, researchers can incorporate more advanced mechanisms for human-AI collaboration or use external knowledge sources to help facilitate communication and coordination between humans and AI systems.\\n10. Limited ability to handle ethical and moral considerations: LMs may struggle with problems that involve ethical or moral considerations. To address this, researchers can incorporate more advanced mechanisms for ethical and moral reasoning or use external knowledge sources to help guide the LM's decision-making process.\\n\\nBy addressing these limitations, researchers can improve the overall ability of LMs to think and reason like humans, leading to more effective and efficient problem-solving capabilities.\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_krishLangChain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
